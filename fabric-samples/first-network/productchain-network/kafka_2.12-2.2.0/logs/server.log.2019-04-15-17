[2019-04-15 17:33:30,976] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-04-15 17:33:31,192] ERROR Exiting Kafka due to fatal exception (kafka.Kafka$)
java.nio.file.NoSuchFileException: config/server-1.properties
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214)
	at java.nio.file.Files.newByteChannel(Files.java:361)
	at java.nio.file.Files.newByteChannel(Files.java:407)
	at java.nio.file.spi.FileSystemProvider.newInputStream(FileSystemProvider.java:384)
	at java.nio.file.Files.newInputStream(Files.java:152)
	at org.apache.kafka.common.utils.Utils.loadProps(Utils.java:564)
	at kafka.Kafka$.getPropsFromArgs(Kafka.scala:42)
	at kafka.Kafka$.main(Kafka.scala:58)
	at kafka.Kafka.main(Kafka.scala)
[2019-04-15 17:35:02,948] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-04-15 17:35:02,969] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-04-15 17:35:02,970] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-04-15 17:35:02,976] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-04-15 17:35:02,976] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-04-15 17:35:02,985] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-04-15 17:35:03,047] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-04-15 17:35:03,071] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-04-15 17:35:03,099] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-04-15 17:35:03,100] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-04-15 17:35:03,102] ERROR Exiting Kafka due to fatal exception (kafka.Kafka$)
java.nio.file.NoSuchFileException: config/server-1.properties
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214)
	at java.nio.file.Files.newByteChannel(Files.java:361)
	at java.nio.file.Files.newByteChannel(Files.java:407)
	at java.nio.file.spi.FileSystemProvider.newInputStream(FileSystemProvider.java:384)
	at java.nio.file.Files.newInputStream(Files.java:152)
	at org.apache.kafka.common.utils.Utils.loadProps(Utils.java:564)
	at kafka.Kafka$.getPropsFromArgs(Kafka.scala:42)
	at kafka.Kafka$.main(Kafka.scala:58)
	at kafka.Kafka.main(Kafka.scala)
[2019-04-15 17:35:03,135] INFO Server environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:35:03,135] INFO Server environment:host.name=shodan (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:35:03,135] INFO Server environment:java.version=1.8.0_181 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:35:03,143] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:35:03,143] INFO Server environment:java.home=/usr/lib/jvm/java-8-oracle/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:35:03,143] INFO Server environment:java.class.path=/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/activation-1.1.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/aopalliance-repackaged-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/argparse4j-0.7.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/audience-annotations-0.5.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/commons-lang3-3.8.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-api-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-basic-auth-extension-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-file-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-json-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-runtime-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-transforms-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/guava-20.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/hk2-api-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/hk2-locator-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/hk2-utils-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-annotations-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-core-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-databind-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-datatype-jdk8-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-jaxrs-base-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-jaxrs-json-provider-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-module-jaxb-annotations-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javassist-3.22.0-CR2.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.annotation-api-1.2.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.inject-1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.inject-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.ws.rs-api-2.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jaxb-api-2.3.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-client-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-common-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-container-servlet-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-container-servlet-core-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-hk2-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-media-jaxb-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-server-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-client-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-continuation-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-http-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-io-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-security-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-server-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-servlet-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-servlets-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-util-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jopt-simple-5.0.4.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka_2.12-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka_2.12-2.2.0-sources.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-clients-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-log4j-appender-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-streams-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-streams-examples-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-streams-scala_2.12-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-streams-test-utils-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-tools-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/log4j-1.2.17.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/lz4-java-1.5.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/maven-artifact-3.6.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/metrics-core-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/plexus-utils-3.1.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/reflections-0.9.11.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/rocksdbjni-5.15.10.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/scala-library-2.12.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/scala-reflect-2.12.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/slf4j-api-1.7.25.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/slf4j-log4j12-1.7.25.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/snappy-java-1.1.7.2.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/validation-api-1.1.0.Final.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/zkclient-0.11.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/zookeeper-3.4.13.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/zstd-jni-1.3.8-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:35:03,145] INFO Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:35:03,151] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:35:03,152] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:35:03,152] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:35:03,152] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:35:03,152] INFO Server environment:os.version=4.15.0-47-generic (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:35:03,153] INFO Server environment:user.name=trench (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:35:03,153] INFO Server environment:user.home=/home/trench (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:35:03,153] INFO Server environment:user.dir=/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:35:03,178] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-04-15 17:35:03,199] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:35:03,199] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:35:03,199] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:35:03,247] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-04-15 17:35:03,262] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-04-15 17:35:03,245] ERROR Exiting Kafka due to fatal exception (kafka.Kafka$)
java.nio.file.NoSuchFileException: config/server-3.properties
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214)
	at java.nio.file.Files.newByteChannel(Files.java:361)
	at java.nio.file.Files.newByteChannel(Files.java:407)
	at java.nio.file.spi.FileSystemProvider.newInputStream(FileSystemProvider.java:384)
	at java.nio.file.Files.newInputStream(Files.java:152)
	at org.apache.kafka.common.utils.Utils.loadProps(Utils.java:564)
	at kafka.Kafka$.getPropsFromArgs(Kafka.scala:42)
	at kafka.Kafka$.main(Kafka.scala:58)
	at kafka.Kafka.main(Kafka.scala)
[2019-04-15 17:35:03,290] ERROR Exiting Kafka due to fatal exception (kafka.Kafka$)
java.nio.file.NoSuchFileException: config/server-2.properties
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214)
	at java.nio.file.Files.newByteChannel(Files.java:361)
	at java.nio.file.Files.newByteChannel(Files.java:407)
	at java.nio.file.spi.FileSystemProvider.newInputStream(FileSystemProvider.java:384)
	at java.nio.file.Files.newInputStream(Files.java:152)
	at org.apache.kafka.common.utils.Utils.loadProps(Utils.java:564)
	at kafka.Kafka$.getPropsFromArgs(Kafka.scala:42)
	at kafka.Kafka$.main(Kafka.scala:58)
	at kafka.Kafka.main(Kafka.scala)
[2019-04-15 17:35:04,343] INFO starting (kafka.server.KafkaServer)
[2019-04-15 17:35:04,344] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-04-15 17:35:04,367] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-04-15 17:35:04,373] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:35:04,373] INFO Client environment:host.name=shodan (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:35:04,373] INFO Client environment:java.version=1.8.0_181 (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:35:04,373] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:35:04,373] INFO Client environment:java.home=/usr/lib/jvm/java-8-oracle/jre (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:35:04,373] INFO Client environment:java.class.path=/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/activation-1.1.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/aopalliance-repackaged-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/argparse4j-0.7.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/audience-annotations-0.5.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/commons-lang3-3.8.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-api-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-basic-auth-extension-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-file-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-json-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-runtime-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-transforms-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/guava-20.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/hk2-api-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/hk2-locator-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/hk2-utils-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-annotations-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-core-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-databind-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-datatype-jdk8-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-jaxrs-base-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-jaxrs-json-provider-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-module-jaxb-annotations-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javassist-3.22.0-CR2.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.annotation-api-1.2.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.inject-1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.inject-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.ws.rs-api-2.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jaxb-api-2.3.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-client-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-common-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-container-servlet-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-container-servlet-core-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-hk2-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-media-jaxb-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-server-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-client-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-continuation-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-http-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-io-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-security-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-server-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-servlet-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-servlets-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-util-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jopt-simple-5.0.4.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka_2.12-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka_2.12-2.2.0-sources.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-clients-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-log4j-appender-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-streams-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-streams-examples-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-streams-scala_2.12-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-streams-test-utils-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-tools-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/log4j-1.2.17.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/lz4-java-1.5.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/maven-artifact-3.6.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/metrics-core-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/plexus-utils-3.1.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/reflections-0.9.11.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/rocksdbjni-5.15.10.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/scala-library-2.12.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/scala-reflect-2.12.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/slf4j-api-1.7.25.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/slf4j-log4j12-1.7.25.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/snappy-java-1.1.7.2.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/validation-api-1.1.0.Final.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/zkclient-0.11.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/zookeeper-3.4.13.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/zstd-jni-1.3.8-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:35:04,374] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:35:04,374] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:35:04,374] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:35:04,374] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:35:04,374] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:35:04,374] INFO Client environment:os.version=4.15.0-47-generic (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:35:04,374] INFO Client environment:user.name=trench (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:35:04,374] INFO Client environment:user.home=/home/trench (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:35:04,374] INFO Client environment:user.dir=/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0 (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:35:04,377] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@29626d54 (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:35:04,391] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-04-15 17:35:04,391] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:35:04,397] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:35:04,398] INFO Accepted socket connection from /127.0.0.1:36094 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-04-15 17:35:04,408] INFO Client attempting to establish new session at /127.0.0.1:36094 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:35:04,411] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-04-15 17:35:04,435] INFO Established session 0x100000343d90000 with negotiated timeout 6000 for client /127.0.0.1:36094 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:35:04,438] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x100000343d90000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:35:04,442] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-04-15 17:35:04,525] INFO Got user-level KeeperException when processing sessionid:0x100000343d90000 type:create cxid:0x2 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:35:04,541] INFO Got user-level KeeperException when processing sessionid:0x100000343d90000 type:create cxid:0x6 zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:35:04,551] INFO Got user-level KeeperException when processing sessionid:0x100000343d90000 type:create cxid:0x9 zxid:0xa txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:35:04,755] INFO Got user-level KeeperException when processing sessionid:0x100000343d90000 type:create cxid:0x15 zxid:0x15 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:35:04,769] INFO Cluster ID = OjZirBKETCOSVwHSS6U7pg (kafka.server.KafkaServer)
[2019-04-15 17:35:04,785] WARN No meta.properties file under dir /tmp/kafka-logs/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-04-15 17:35:04,874] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.2-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.2-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-04-15 17:35:04,891] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.2-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.2-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-04-15 17:35:04,926] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:35:04,926] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:35:04,928] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:35:04,959] INFO Log directory /tmp/kafka-logs not found, creating it. (kafka.log.LogManager)
[2019-04-15 17:35:04,968] INFO Loading logs. (kafka.log.LogManager)
[2019-04-15 17:35:04,980] INFO Logs loading complete in 12 ms. (kafka.log.LogManager)
[2019-04-15 17:35:04,998] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-04-15 17:35:05,005] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-04-15 17:35:05,407] INFO Awaiting socket connections on s0.0.0.0:9092. (kafka.network.Acceptor)
[2019-04-15 17:35:05,456] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-04-15 17:35:05,459] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-04-15 17:35:05,502] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:35:05,504] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:35:05,506] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:35:05,508] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:35:05,526] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-04-15 17:35:05,555] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-04-15 17:35:05,579] INFO Stat of the created znode at /brokers/ids/0 is: 24,24,1555313705569,1555313705569,1,0,0,72057608061124608,182,0,24
 (kafka.zk.KafkaZkClient)
[2019-04-15 17:35:05,580] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(shodan,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 24 (kafka.zk.KafkaZkClient)
[2019-04-15 17:35:05,583] WARN No meta.properties file under dir /tmp/kafka-logs/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-04-15 17:35:05,675] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:35:05,680] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:35:05,687] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:35:05,696] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[2019-04-15 17:35:05,708] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-04-15 17:35:05,716] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-04-15 17:35:05,719] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 8 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-04-15 17:35:05,742] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1 (kafka.coordinator.transaction.ProducerIdManager)
[2019-04-15 17:35:05,781] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-04-15 17:35:05,787] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-04-15 17:35:05,789] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-04-15 17:35:05,903] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-04-15 17:35:05,920] INFO Got user-level KeeperException when processing sessionid:0x100000343d90000 type:multi cxid:0x37 zxid:0x1c txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:35:05,938] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2019-04-15 17:35:05,953] INFO Kafka version: 2.2.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-04-15 17:35:05,955] INFO Kafka commitId: 05fcfde8f69b0349 (org.apache.kafka.common.utils.AppInfoParser)
[2019-04-15 17:35:05,959] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2019-04-15 17:35:06,220] INFO [Admin Manager on Broker 0]: Error processing create topic request for topic orderer with arguments (numPartitions=1, replicationFactor=4, replicasAssignments={}, configs={}) (kafka.server.AdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 4 larger than available brokers: 1.
[2019-04-15 17:35:15,405] INFO Unable to read additional data from server sessionid 0x100000343d90000, likely server has closed socket, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:35:16,857] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:35:16,859] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:35:18,025] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:35:18,026] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:35:19,495] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:35:19,495] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:35:21,573] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:35:21,574] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:35:23,641] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:35:23,642] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:35:24,995] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:35:24,998] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:35:26,249] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:35:26,250] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:35:27,478] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:35:27,479] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:35:29,124] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:35:29,125] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:35:31,156] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:35:31,157] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:35:33,157] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:35:33,158] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:35:34,397] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:35:34,398] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:35:35,770] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:35:35,771] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:35:37,649] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:35:37,650] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:35:39,526] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:35:39,527] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:35:41,030] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:35:41,031] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:35:42,815] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:35:42,816] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:35:44,393] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:35:44,395] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:35:46,106] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:35:46,107] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:35:48,144] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:35:48,145] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:35:49,373] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:35:49,374] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:35:50,973] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:35:50,974] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:35:52,368] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:35:52,370] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:35:54,185] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:35:54,186] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:35:55,837] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:35:55,838] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:35:57,687] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:35:57,688] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:35:59,740] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:35:59,741] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:01,508] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:01,510] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:02,638] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:02,639] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:04,306] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:04,308] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:05,780] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:05,781] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:07,012] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:07,013] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:08,447] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:08,449] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:10,208] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:10,209] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:11,894] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:11,896] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:13,299] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:13,300] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:14,783] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:14,784] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:16,090] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:16,091] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:17,809] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:17,810] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:19,679] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:19,680] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:21,711] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:21,712] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:23,214] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:23,215] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:24,455] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:24,456] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:25,758] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:25,759] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:27,443] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:27,444] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:28,962] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:28,963] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:30,996] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:30,997] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:32,603] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:32,604] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:33,913] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:33,913] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:35,375] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:35,376] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:37,000] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:37,001] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:38,368] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:38,369] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:40,200] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:40,201] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:41,437] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:41,438] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:42,966] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:42,967] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:44,250] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:44,251] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:45,969] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:45,970] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:47,205] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:47,206] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:48,708] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:48,709] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:49,917] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:49,918] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:51,632] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:51,633] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:53,483] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:53,484] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:54,644] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:54,645] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:56,555] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:56,556] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:58,631] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:58,632] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:59,851] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:36:59,852] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:01,939] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:01,940] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:03,210] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:03,211] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:05,168] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:05,169] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:06,273] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:06,274] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:08,201] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:08,201] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:10,168] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:10,169] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:12,005] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:12,006] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:13,333] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:13,334] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:14,818] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:14,819] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:16,049] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:16,051] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:18,107] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:18,108] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:20,053] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:20,054] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:21,443] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:21,444] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:22,861] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:22,862] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:24,673] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:24,674] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:25,979] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:25,980] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:27,720] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:27,721] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:29,297] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:29,299] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:31,146] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:31,148] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:32,716] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:32,717] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:34,737] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:34,738] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:36,498] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:36,499] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:38,513] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:38,514] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:40,125] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:40,126] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:42,145] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:42,146] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:43,615] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:43,616] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:44,841] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:44,842] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:46,624] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:46,625] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:48,121] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:48,122] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:49,422] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:49,423] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:50,608] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:50,609] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:51,799] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:51,800] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:53,807] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:53,808] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:54,995] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:54,996] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:56,784] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:56,785] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:58,113] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:58,114] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:59,985] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:37:59,986] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:38:01,311] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:38:01,312] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:38:02,687] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:38:02,688] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:38:03,817] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:38:03,818] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:38:05,757] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:38:05,758] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:38:06,924] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:38:06,925] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:38:08,280] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:38:08,281] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:38:10,035] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:38:10,036] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:38:11,646] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:38:11,647] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:38:13,734] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:38:13,735] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:38:14,913] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:38:14,914] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:38:16,830] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:38:16,831] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:38:18,029] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:38:18,030] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:38:19,274] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:38:19,275] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:38:21,331] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:38:21,332] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:38:22,556] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:38:22,557] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:38:24,400] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:38:24,401] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:38:25,580] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:38:25,581] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:38:27,675] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:38:27,676] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:38:29,033] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:38:29,034] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:38:29,874] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-04-15 17:38:29,878] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-04-15 17:38:29,878] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-04-15 17:38:29,882] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-04-15 17:38:29,882] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-04-15 17:38:29,905] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-04-15 17:38:29,906] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-04-15 17:38:29,917] INFO Server environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:38:29,917] INFO Server environment:host.name=shodan (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:38:29,917] INFO Server environment:java.version=1.8.0_181 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:38:29,918] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:38:29,918] INFO Server environment:java.home=/usr/lib/jvm/java-8-oracle/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:38:29,918] INFO Server environment:java.class.path=/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/activation-1.1.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/aopalliance-repackaged-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/argparse4j-0.7.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/audience-annotations-0.5.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/commons-lang3-3.8.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-api-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-basic-auth-extension-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-file-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-json-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-runtime-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-transforms-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/guava-20.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/hk2-api-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/hk2-locator-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/hk2-utils-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-annotations-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-core-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-databind-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-datatype-jdk8-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-jaxrs-base-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-jaxrs-json-provider-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-module-jaxb-annotations-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javassist-3.22.0-CR2.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.annotation-api-1.2.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.inject-1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.inject-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.ws.rs-api-2.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jaxb-api-2.3.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-client-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-common-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-container-servlet-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-container-servlet-core-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-hk2-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-media-jaxb-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-server-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-client-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-continuation-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-http-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-io-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-security-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-server-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-servlet-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-servlets-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-util-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jopt-simple-5.0.4.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka_2.12-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka_2.12-2.2.0-sources.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-clients-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-log4j-appender-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-streams-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-streams-examples-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-streams-scala_2.12-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-streams-test-utils-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-tools-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/log4j-1.2.17.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/lz4-java-1.5.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/maven-artifact-3.6.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/metrics-core-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/plexus-utils-3.1.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/reflections-0.9.11.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/rocksdbjni-5.15.10.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/scala-library-2.12.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/scala-reflect-2.12.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/slf4j-api-1.7.25.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/slf4j-log4j12-1.7.25.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/snappy-java-1.1.7.2.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/validation-api-1.1.0.Final.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/zkclient-0.11.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/zookeeper-3.4.13.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/zstd-jni-1.3.8-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:38:29,919] INFO Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:38:29,919] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:38:29,919] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:38:29,919] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:38:29,919] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:38:29,919] INFO Server environment:os.version=4.15.0-47-generic (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:38:29,919] INFO Server environment:user.name=trench (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:38:29,919] INFO Server environment:user.home=/home/trench (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:38:29,919] INFO Server environment:user.dir=/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:38:29,931] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:38:29,931] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:38:29,931] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:38:29,940] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-04-15 17:38:29,945] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-04-15 17:38:30,177] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:38:30,178] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:38:30,183] INFO Accepted socket connection from /127.0.0.1:36350 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-04-15 17:38:30,193] INFO Refusing session request for client /127.0.0.1:36350 as it has seen zxid 0x1c our last zxid is 0x0 client must try another server (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:38:30,193] INFO Closed socket connection for client /127.0.0.1:36350 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-04-15 17:38:30,194] INFO Unable to read additional data from server sessionid 0x100000343d90000, likely server has closed socket, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:38:31,413] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:38:31,414] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:38:31,414] INFO Accepted socket connection from /127.0.0.1:36352 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-04-15 17:38:31,416] INFO Refusing session request for client /127.0.0.1:36352 as it has seen zxid 0x1c our last zxid is 0x0 client must try another server (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:38:31,417] INFO Closed socket connection for client /127.0.0.1:36352 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-04-15 17:38:31,418] INFO Unable to read additional data from server sessionid 0x100000343d90000, likely server has closed socket, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:38:33,227] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:38:33,228] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:38:33,228] INFO Accepted socket connection from /127.0.0.1:36354 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-04-15 17:38:33,229] INFO Refusing session request for client /127.0.0.1:36354 as it has seen zxid 0x1c our last zxid is 0x0 client must try another server (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:38:33,230] INFO Closed socket connection for client /127.0.0.1:36354 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-04-15 17:38:33,230] INFO Unable to read additional data from server sessionid 0x100000343d90000, likely server has closed socket, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:38:33,836] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-04-15 17:38:33,907] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-04-15 17:38:33,941] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-04-15 17:38:33,949] ERROR Exiting Kafka due to fatal exception (kafka.Kafka$)
java.nio.file.NoSuchFileException: config/server-3.properties
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214)
	at java.nio.file.Files.newByteChannel(Files.java:361)
	at java.nio.file.Files.newByteChannel(Files.java:407)
	at java.nio.file.spi.FileSystemProvider.newInputStream(FileSystemProvider.java:384)
	at java.nio.file.Files.newInputStream(Files.java:152)
	at org.apache.kafka.common.utils.Utils.loadProps(Utils.java:564)
	at kafka.Kafka$.getPropsFromArgs(Kafka.scala:42)
	at kafka.Kafka$.main(Kafka.scala:58)
	at kafka.Kafka.main(Kafka.scala)
[2019-04-15 17:38:34,019] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-04-15 17:38:34,031] ERROR Exiting Kafka due to fatal exception (kafka.Kafka$)
java.nio.file.NoSuchFileException: config/server-1.properties
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214)
	at java.nio.file.Files.newByteChannel(Files.java:361)
	at java.nio.file.Files.newByteChannel(Files.java:407)
	at java.nio.file.spi.FileSystemProvider.newInputStream(FileSystemProvider.java:384)
	at java.nio.file.Files.newInputStream(Files.java:152)
	at org.apache.kafka.common.utils.Utils.loadProps(Utils.java:564)
	at kafka.Kafka$.getPropsFromArgs(Kafka.scala:42)
	at kafka.Kafka$.main(Kafka.scala:58)
	at kafka.Kafka.main(Kafka.scala)
[2019-04-15 17:38:34,120] ERROR Exiting Kafka due to fatal exception (kafka.Kafka$)
java.nio.file.NoSuchFileException: config/server-2.properties
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214)
	at java.nio.file.Files.newByteChannel(Files.java:361)
	at java.nio.file.Files.newByteChannel(Files.java:407)
	at java.nio.file.spi.FileSystemProvider.newInputStream(FileSystemProvider.java:384)
	at java.nio.file.Files.newInputStream(Files.java:152)
	at org.apache.kafka.common.utils.Utils.loadProps(Utils.java:564)
	at kafka.Kafka$.getPropsFromArgs(Kafka.scala:42)
	at kafka.Kafka$.main(Kafka.scala:58)
	at kafka.Kafka.main(Kafka.scala)
[2019-04-15 17:38:34,512] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:38:34,513] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:38:34,513] INFO Accepted socket connection from /127.0.0.1:36356 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-04-15 17:38:34,514] INFO Refusing session request for client /127.0.0.1:36356 as it has seen zxid 0x1c our last zxid is 0x0 client must try another server (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:38:34,514] INFO Closed socket connection for client /127.0.0.1:36356 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-04-15 17:38:34,514] INFO Unable to read additional data from server sessionid 0x100000343d90000, likely server has closed socket, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:38:34,910] INFO starting (kafka.server.KafkaServer)
[2019-04-15 17:38:34,912] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-04-15 17:38:34,936] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-04-15 17:38:34,943] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:38:34,944] INFO Client environment:host.name=shodan (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:38:34,944] INFO Client environment:java.version=1.8.0_181 (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:38:34,944] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:38:34,944] INFO Client environment:java.home=/usr/lib/jvm/java-8-oracle/jre (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:38:34,944] INFO Client environment:java.class.path=/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/activation-1.1.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/aopalliance-repackaged-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/argparse4j-0.7.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/audience-annotations-0.5.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/commons-lang3-3.8.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-api-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-basic-auth-extension-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-file-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-json-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-runtime-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-transforms-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/guava-20.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/hk2-api-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/hk2-locator-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/hk2-utils-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-annotations-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-core-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-databind-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-datatype-jdk8-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-jaxrs-base-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-jaxrs-json-provider-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-module-jaxb-annotations-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javassist-3.22.0-CR2.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.annotation-api-1.2.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.inject-1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.inject-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.ws.rs-api-2.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jaxb-api-2.3.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-client-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-common-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-container-servlet-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-container-servlet-core-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-hk2-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-media-jaxb-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-server-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-client-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-continuation-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-http-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-io-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-security-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-server-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-servlet-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-servlets-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-util-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jopt-simple-5.0.4.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka_2.12-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka_2.12-2.2.0-sources.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-clients-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-log4j-appender-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-streams-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-streams-examples-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-streams-scala_2.12-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-streams-test-utils-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-tools-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/log4j-1.2.17.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/lz4-java-1.5.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/maven-artifact-3.6.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/metrics-core-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/plexus-utils-3.1.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/reflections-0.9.11.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/rocksdbjni-5.15.10.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/scala-library-2.12.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/scala-reflect-2.12.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/slf4j-api-1.7.25.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/slf4j-log4j12-1.7.25.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/snappy-java-1.1.7.2.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/validation-api-1.1.0.Final.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/zkclient-0.11.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/zookeeper-3.4.13.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/zstd-jni-1.3.8-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:38:34,945] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:38:34,945] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:38:34,945] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:38:34,945] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:38:34,945] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:38:34,945] INFO Client environment:os.version=4.15.0-47-generic (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:38:34,946] INFO Client environment:user.name=trench (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:38:34,946] INFO Client environment:user.home=/home/trench (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:38:34,946] INFO Client environment:user.dir=/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0 (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:38:34,947] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@29626d54 (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:38:34,963] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-04-15 17:38:34,963] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:38:34,970] INFO Accepted socket connection from /127.0.0.1:36358 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-04-15 17:38:34,970] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:38:34,974] INFO Client attempting to establish new session at /127.0.0.1:36358 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:38:34,977] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-04-15 17:38:34,997] INFO Established session 0x10000066afd0000 with negotiated timeout 6000 for client /127.0.0.1:36358 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:38:34,999] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10000066afd0000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:38:35,003] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-04-15 17:38:35,088] INFO Got user-level KeeperException when processing sessionid:0x10000066afd0000 type:create cxid:0x2 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:38:35,099] ERROR Error while reading checkpoint file /tmp/kafka-logs/cleaner-offset-checkpoint (kafka.server.LogDirFailureChannel)
java.nio.file.NoSuchFileException: /tmp/kafka-logs/cleaner-offset-checkpoint
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214)
	at java.nio.file.Files.newByteChannel(Files.java:361)
	at java.nio.file.Files.newByteChannel(Files.java:407)
	at java.nio.file.spi.FileSystemProvider.newInputStream(FileSystemProvider.java:384)
	at java.nio.file.Files.newInputStream(Files.java:152)
	at java.nio.file.Files.newBufferedReader(Files.java:2784)
	at java.nio.file.Files.newBufferedReader(Files.java:2816)
	at kafka.server.checkpoints.CheckpointFile.liftedTree2$1(CheckpointFile.scala:87)
	at kafka.server.checkpoints.CheckpointFile.read(CheckpointFile.scala:86)
	at kafka.server.checkpoints.OffsetCheckpointFile.read(OffsetCheckpointFile.scala:61)
	at kafka.log.LogCleanerManager.$anonfun$allCleanerCheckpoints$2(LogCleanerManager.scala:135)
	at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:244)
	at scala.collection.Iterator.foreach(Iterator.scala:941)
	at scala.collection.Iterator.foreach$(Iterator.scala:941)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1429)
	at scala.collection.MapLike$DefaultValuesIterable.foreach(MapLike.scala:213)
	at scala.collection.TraversableLike.flatMap(TraversableLike.scala:244)
	at scala.collection.TraversableLike.flatMap$(TraversableLike.scala:241)
	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:108)
	at kafka.log.LogCleanerManager.$anonfun$allCleanerCheckpoints$1(LogCleanerManager.scala:133)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:251)
	at kafka.log.LogCleanerManager.allCleanerCheckpoints(LogCleanerManager.scala:141)
	at kafka.log.LogCleanerManager.$anonfun$grabFilthiestCompactedLog$1(LogCleanerManager.scala:172)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:251)
	at kafka.log.LogCleanerManager.grabFilthiestCompactedLog(LogCleanerManager.scala:169)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:313)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:300)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-04-15 17:38:35,100] INFO [ReplicaManager broker=0] Stopping serving replicas in dir /tmp/kafka-logs (kafka.server.ReplicaManager)
[2019-04-15 17:38:35,105] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set() (kafka.server.ReplicaFetcherManager)
[2019-04-15 17:38:35,106] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set() (kafka.server.ReplicaAlterLogDirsManager)
[2019-04-15 17:38:35,111] INFO Got user-level KeeperException when processing sessionid:0x10000066afd0000 type:create cxid:0x6 zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:38:35,124] INFO [ReplicaManager broker=0] Broker 0 stopped fetcher for partitions  and stopped moving logs for partitions  because they are in the failed log directory /tmp/kafka-logs. (kafka.server.ReplicaManager)
[2019-04-15 17:38:35,125] INFO Stopping serving logs in dir /tmp/kafka-logs (kafka.log.LogManager)
[2019-04-15 17:38:35,126] INFO Got user-level KeeperException when processing sessionid:0x10000066afd0000 type:create cxid:0x9 zxid:0xa txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:38:35,129] ERROR Shutdown broker because all log dirs in /tmp/kafka-logs have failed (kafka.log.LogManager)
[2019-04-15 17:38:35,351] INFO Got user-level KeeperException when processing sessionid:0x10000066afd0000 type:create cxid:0x15 zxid:0x15 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:38:35,374] INFO Cluster ID = LuFRCFWHSm2wwCzAdet_Kw (kafka.server.KafkaServer)
[2019-04-15 17:38:35,380] WARN No meta.properties file under dir /tmp/kafka-logs/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-04-15 17:38:35,468] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.2-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.2-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-04-15 17:38:35,485] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.2-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.2-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-04-15 17:38:35,522] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:38:35,522] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:38:35,524] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:38:35,556] INFO Log directory /tmp/kafka-logs not found, creating it. (kafka.log.LogManager)
[2019-04-15 17:38:35,565] INFO Loading logs. (kafka.log.LogManager)
[2019-04-15 17:38:35,576] INFO Logs loading complete in 11 ms. (kafka.log.LogManager)
[2019-04-15 17:38:35,592] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-04-15 17:38:35,597] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-04-15 17:38:35,988] INFO Awaiting socket connections on s0.0.0.0:9092. (kafka.network.Acceptor)
[2019-04-15 17:38:36,032] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-04-15 17:38:36,035] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-04-15 17:38:36,064] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:38:36,067] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:38:36,068] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:38:36,069] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:38:36,085] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-04-15 17:38:36,113] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-04-15 17:38:36,144] INFO Stat of the created znode at /brokers/ids/0 is: 24,24,1555313916126,1555313916126,1,0,0,72057621602697216,182,0,24
 (kafka.zk.KafkaZkClient)
[2019-04-15 17:38:36,145] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(shodan,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 24 (kafka.zk.KafkaZkClient)
[2019-04-15 17:38:36,148] WARN No meta.properties file under dir /tmp/kafka-logs/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-04-15 17:38:36,237] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:38:36,242] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:38:36,244] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:38:36,261] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[2019-04-15 17:38:36,278] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-04-15 17:38:36,287] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-04-15 17:38:36,298] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 11 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-04-15 17:38:36,321] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1 (kafka.coordinator.transaction.ProducerIdManager)
[2019-04-15 17:38:36,370] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-04-15 17:38:36,376] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-04-15 17:38:36,380] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-04-15 17:38:36,477] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-04-15 17:38:36,503] INFO Got user-level KeeperException when processing sessionid:0x10000066afd0000 type:multi cxid:0x38 zxid:0x1c txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:38:36,507] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2019-04-15 17:38:36,529] INFO Kafka version: 2.2.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-04-15 17:38:36,529] INFO Kafka commitId: 05fcfde8f69b0349 (org.apache.kafka.common.utils.AppInfoParser)
[2019-04-15 17:38:36,535] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2019-04-15 17:38:38,732] INFO [Admin Manager on Broker 0]: Error processing create topic request for topic orderer with arguments (numPartitions=1, replicationFactor=4, replicasAssignments={}, configs={}) (kafka.server.AdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 4 larger than available brokers: 1.
[2019-04-15 17:39:11,261] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-04-15 17:39:11,264] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2019-04-15 17:39:11,266] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2019-04-15 17:39:11,291] INFO [KafkaServer id=0] Controlled shutdown succeeded (kafka.server.KafkaServer)
[2019-04-15 17:39:11,298] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-04-15 17:39:11,299] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-04-15 17:39:11,300] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-04-15 17:39:11,301] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2019-04-15 17:39:11,324] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2019-04-15 17:39:11,327] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2019-04-15 17:39:11,331] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2019-04-15 17:39:11,335] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2019-04-15 17:39:11,338] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:39:11,468] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:39:11,468] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:39:11,477] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-04-15 17:39:11,478] INFO [ProducerId Manager 0]: Shutdown complete: last producerId assigned 0 (kafka.coordinator.transaction.ProducerIdManager)
[2019-04-15 17:39:11,480] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2019-04-15 17:39:11,480] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-04-15 17:39:11,480] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-04-15 17:39:11,481] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-04-15 17:39:11,481] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-04-15 17:39:11,483] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2019-04-15 17:39:11,484] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:39:11,670] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:39:11,670] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:39:11,671] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:39:11,672] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:39:11,672] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:39:11,676] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2019-04-15 17:39:11,681] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2019-04-15 17:39:11,682] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-04-15 17:39:11,682] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-04-15 17:39:11,683] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-04-15 17:39:11,684] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2019-04-15 17:39:11,687] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2019-04-15 17:39:11,689] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2019-04-15 17:39:11,691] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2019-04-15 17:39:11,691] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:39:11,692] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:39:11,692] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:39:11,693] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:39:11,892] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:39:11,893] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:39:11,894] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:39:11,894] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:39:11,894] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:39:11,895] INFO [ExpirationReaper-0-ElectPreferredLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:39:11,895] INFO [ExpirationReaper-0-ElectPreferredLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:39:11,895] INFO [ExpirationReaper-0-ElectPreferredLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:39:11,903] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2019-04-15 17:39:11,905] INFO Shutting down. (kafka.log.LogManager)
[2019-04-15 17:39:11,946] INFO Shutdown complete. (kafka.log.LogManager)
[2019-04-15 17:39:11,958] INFO [ZooKeeperClient] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-04-15 17:39:11,959] INFO Processed session termination for sessionid: 0x10000066afd0000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:39:11,965] INFO Closed socket connection for client /127.0.0.1:36358 which had sessionid 0x10000066afd0000 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-04-15 17:39:11,965] INFO EventThread shut down for session: 0x10000066afd0000 (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:39:11,965] INFO Session: 0x10000066afd0000 closed (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:39:11,969] INFO [ZooKeeperClient] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-04-15 17:39:11,969] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:39:12,528] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:39:12,528] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:39:12,529] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:39:13,528] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:39:13,528] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:39:13,529] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:39:13,530] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:39:13,530] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:39:13,534] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer)
[2019-04-15 17:39:13,574] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer)
[2019-04-15 17:39:13,578] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2019-04-15 17:45:32,589] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-04-15 17:45:32,593] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-04-15 17:45:32,593] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-04-15 17:45:32,597] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-04-15 17:45:32,597] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-04-15 17:45:32,621] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-04-15 17:45:32,622] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-04-15 17:45:32,632] INFO Server environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:45:32,632] INFO Server environment:host.name=shodan (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:45:32,632] INFO Server environment:java.version=1.8.0_181 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:45:32,632] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:45:32,633] INFO Server environment:java.home=/usr/lib/jvm/java-8-oracle/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:45:32,633] INFO Server environment:java.class.path=/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/activation-1.1.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/aopalliance-repackaged-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/argparse4j-0.7.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/audience-annotations-0.5.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/commons-lang3-3.8.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-api-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-basic-auth-extension-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-file-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-json-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-runtime-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-transforms-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/guava-20.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/hk2-api-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/hk2-locator-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/hk2-utils-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-annotations-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-core-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-databind-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-datatype-jdk8-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-jaxrs-base-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-jaxrs-json-provider-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-module-jaxb-annotations-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javassist-3.22.0-CR2.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.annotation-api-1.2.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.inject-1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.inject-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.ws.rs-api-2.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jaxb-api-2.3.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-client-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-common-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-container-servlet-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-container-servlet-core-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-hk2-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-media-jaxb-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-server-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-client-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-continuation-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-http-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-io-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-security-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-server-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-servlet-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-servlets-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-util-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jopt-simple-5.0.4.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka_2.12-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka_2.12-2.2.0-sources.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-clients-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-log4j-appender-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-streams-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-streams-examples-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-streams-scala_2.12-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-streams-test-utils-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-tools-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/log4j-1.2.17.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/lz4-java-1.5.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/maven-artifact-3.6.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/metrics-core-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/plexus-utils-3.1.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/reflections-0.9.11.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/rocksdbjni-5.15.10.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/scala-library-2.12.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/scala-reflect-2.12.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/slf4j-api-1.7.25.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/slf4j-log4j12-1.7.25.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/snappy-java-1.1.7.2.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/validation-api-1.1.0.Final.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/zkclient-0.11.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/zookeeper-3.4.13.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/zstd-jni-1.3.8-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:45:32,634] INFO Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:45:32,634] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:45:32,634] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:45:32,634] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:45:32,634] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:45:32,634] INFO Server environment:os.version=4.15.0-47-generic (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:45:32,634] INFO Server environment:user.name=trench (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:45:32,634] INFO Server environment:user.home=/home/trench (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:45:32,634] INFO Server environment:user.dir=/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:45:32,645] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:45:32,645] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:45:32,645] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:45:32,655] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-04-15 17:45:32,660] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-04-15 17:45:36,584] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-04-15 17:45:36,615] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-04-15 17:45:36,691] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-04-15 17:45:36,695] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-04-15 17:45:37,958] INFO starting (kafka.server.KafkaServer)
[2019-04-15 17:45:37,967] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-04-15 17:45:37,968] INFO starting (kafka.server.KafkaServer)
[2019-04-15 17:45:37,974] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-04-15 17:45:38,020] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-04-15 17:45:38,033] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:38,034] INFO Client environment:host.name=shodan (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:38,036] INFO Client environment:java.version=1.8.0_181 (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:38,037] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-04-15 17:45:38,037] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:38,041] INFO Client environment:java.home=/usr/lib/jvm/java-8-oracle/jre (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:38,042] INFO Client environment:java.class.path=/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/activation-1.1.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/aopalliance-repackaged-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/argparse4j-0.7.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/audience-annotations-0.5.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/commons-lang3-3.8.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-api-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-basic-auth-extension-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-file-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-json-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-runtime-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-transforms-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/guava-20.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/hk2-api-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/hk2-locator-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/hk2-utils-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-annotations-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-core-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-databind-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-datatype-jdk8-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-jaxrs-base-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-jaxrs-json-provider-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-module-jaxb-annotations-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javassist-3.22.0-CR2.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.annotation-api-1.2.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.inject-1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.inject-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.ws.rs-api-2.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jaxb-api-2.3.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-client-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-common-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-container-servlet-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-container-servlet-core-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-hk2-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-media-jaxb-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-server-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-client-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-continuation-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-http-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-io-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-security-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-server-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-servlet-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-servlets-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-util-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jopt-simple-5.0.4.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka_2.12-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka_2.12-2.2.0-sources.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-clients-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-log4j-appender-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-streams-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-streams-examples-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-streams-scala_2.12-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-streams-test-utils-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-tools-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/log4j-1.2.17.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/lz4-java-1.5.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/maven-artifact-3.6.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/metrics-core-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/plexus-utils-3.1.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/reflections-0.9.11.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/rocksdbjni-5.15.10.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/scala-library-2.12.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/scala-reflect-2.12.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/slf4j-api-1.7.25.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/slf4j-log4j12-1.7.25.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/snappy-java-1.1.7.2.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/validation-api-1.1.0.Final.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/zkclient-0.11.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/zookeeper-3.4.13.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/zstd-jni-1.3.8-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:38,043] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:38,043] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:38,052] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:38,053] INFO Client environment:host.name=shodan (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:38,053] INFO Client environment:java.version=1.8.0_181 (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:38,053] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:38,044] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:38,053] INFO Client environment:java.home=/usr/lib/jvm/java-8-oracle/jre (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:38,056] INFO Client environment:java.class.path=/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/activation-1.1.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/aopalliance-repackaged-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/argparse4j-0.7.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/audience-annotations-0.5.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/commons-lang3-3.8.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-api-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-basic-auth-extension-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-file-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-json-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-runtime-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-transforms-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/guava-20.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/hk2-api-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/hk2-locator-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/hk2-utils-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-annotations-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-core-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-databind-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-datatype-jdk8-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-jaxrs-base-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-jaxrs-json-provider-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-module-jaxb-annotations-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javassist-3.22.0-CR2.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.annotation-api-1.2.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.inject-1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.inject-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.ws.rs-api-2.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jaxb-api-2.3.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-client-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-common-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-container-servlet-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-container-servlet-core-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-hk2-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-media-jaxb-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-server-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-client-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-continuation-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-http-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-io-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-security-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-server-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-servlet-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-servlets-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-util-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jopt-simple-5.0.4.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka_2.12-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka_2.12-2.2.0-sources.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-clients-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-log4j-appender-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-streams-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-streams-examples-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-streams-scala_2.12-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-streams-test-utils-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-tools-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/log4j-1.2.17.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/lz4-java-1.5.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/maven-artifact-3.6.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/metrics-core-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/plexus-utils-3.1.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/reflections-0.9.11.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/rocksdbjni-5.15.10.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/scala-library-2.12.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/scala-reflect-2.12.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/slf4j-api-1.7.25.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/slf4j-log4j12-1.7.25.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/snappy-java-1.1.7.2.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/validation-api-1.1.0.Final.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/zkclient-0.11.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/zookeeper-3.4.13.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/zstd-jni-1.3.8-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:38,057] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:38,058] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:38,058] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:38,058] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:38,058] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:38,058] INFO Client environment:os.version=4.15.0-47-generic (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:38,058] INFO Client environment:user.name=trench (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:38,059] INFO Client environment:user.home=/home/trench (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:38,060] INFO Client environment:user.dir=/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0 (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:38,062] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@29626d54 (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:38,056] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:38,068] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:38,069] INFO Client environment:os.version=4.15.0-47-generic (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:38,070] INFO Client environment:user.name=trench (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:38,070] INFO Client environment:user.home=/home/trench (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:38,070] INFO Client environment:user.dir=/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0 (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:38,076] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@29626d54 (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:38,096] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:45:38,101] INFO starting (kafka.server.KafkaServer)
[2019-04-15 17:45:38,103] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-04-15 17:45:38,107] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-04-15 17:45:38,119] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:45:38,121] INFO Accepted socket connection from /127.0.0.1:36370 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-04-15 17:45:38,125] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:45:38,126] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-04-15 17:45:38,133] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:45:38,141] INFO starting (kafka.server.KafkaServer)
[2019-04-15 17:45:38,144] INFO Client attempting to establish new session at /127.0.0.1:36370 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:45:38,145] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-04-15 17:45:38,148] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-04-15 17:45:38,149] INFO Accepted socket connection from /127.0.0.1:36372 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-04-15 17:45:38,153] INFO Client attempting to establish new session at /127.0.0.1:36372 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:45:38,160] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-04-15 17:45:38,170] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:38,170] INFO Client environment:host.name=shodan (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:38,170] INFO Client environment:java.version=1.8.0_181 (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:38,170] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:38,170] INFO Client environment:java.home=/usr/lib/jvm/java-8-oracle/jre (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:38,171] INFO Client environment:java.class.path=/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/activation-1.1.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/aopalliance-repackaged-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/argparse4j-0.7.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/audience-annotations-0.5.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/commons-lang3-3.8.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-api-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-basic-auth-extension-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-file-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-json-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-runtime-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-transforms-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/guava-20.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/hk2-api-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/hk2-locator-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/hk2-utils-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-annotations-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-core-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-databind-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-datatype-jdk8-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-jaxrs-base-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-jaxrs-json-provider-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-module-jaxb-annotations-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javassist-3.22.0-CR2.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.annotation-api-1.2.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.inject-1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.inject-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.ws.rs-api-2.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jaxb-api-2.3.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-client-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-common-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-container-servlet-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-container-servlet-core-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-hk2-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-media-jaxb-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-server-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-client-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-continuation-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-http-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-io-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-security-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-server-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-servlet-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-servlets-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-util-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jopt-simple-5.0.4.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka_2.12-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka_2.12-2.2.0-sources.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-clients-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-log4j-appender-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-streams-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-streams-examples-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-streams-scala_2.12-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-streams-test-utils-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-tools-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/log4j-1.2.17.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/lz4-java-1.5.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/maven-artifact-3.6.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/metrics-core-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/plexus-utils-3.1.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/reflections-0.9.11.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/rocksdbjni-5.15.10.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/scala-library-2.12.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/scala-reflect-2.12.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/slf4j-api-1.7.25.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/slf4j-log4j12-1.7.25.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/snappy-java-1.1.7.2.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/validation-api-1.1.0.Final.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/zkclient-0.11.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/zookeeper-3.4.13.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/zstd-jni-1.3.8-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:38,172] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:38,172] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:38,172] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:38,172] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:38,172] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:38,172] INFO Client environment:os.version=4.15.0-47-generic (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:38,172] INFO Client environment:user.name=trench (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:38,172] INFO Client environment:user.home=/home/trench (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:38,172] INFO Client environment:user.dir=/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0 (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:38,175] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@29626d54 (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:38,176] INFO Established session 0x100000cde360000 with negotiated timeout 6000 for client /127.0.0.1:36370 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:45:38,179] INFO Established session 0x100000cde360001 with negotiated timeout 6000 for client /127.0.0.1:36372 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:45:38,179] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x100000cde360000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:45:38,186] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x100000cde360001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:45:38,186] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-04-15 17:45:38,194] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-04-15 17:45:38,206] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-04-15 17:45:38,218] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:38,219] INFO Client environment:host.name=shodan (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:38,219] INFO Client environment:java.version=1.8.0_181 (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:38,219] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:38,219] INFO Client environment:java.home=/usr/lib/jvm/java-8-oracle/jre (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:38,219] INFO Client environment:java.class.path=/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/activation-1.1.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/aopalliance-repackaged-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/argparse4j-0.7.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/audience-annotations-0.5.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/commons-lang3-3.8.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-api-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-basic-auth-extension-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-file-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-json-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-runtime-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-transforms-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/guava-20.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/hk2-api-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/hk2-locator-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/hk2-utils-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-annotations-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-core-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-databind-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-datatype-jdk8-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-jaxrs-base-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-jaxrs-json-provider-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-module-jaxb-annotations-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javassist-3.22.0-CR2.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.annotation-api-1.2.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.inject-1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.inject-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.ws.rs-api-2.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jaxb-api-2.3.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-client-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-common-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-container-servlet-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-container-servlet-core-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-hk2-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-media-jaxb-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-server-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-client-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-continuation-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-http-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-io-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-security-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-server-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-servlet-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-servlets-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-util-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jopt-simple-5.0.4.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka_2.12-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka_2.12-2.2.0-sources.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-clients-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-log4j-appender-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-streams-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-streams-examples-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-streams-scala_2.12-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-streams-test-utils-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-tools-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/log4j-1.2.17.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/lz4-java-1.5.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/maven-artifact-3.6.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/metrics-core-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/plexus-utils-3.1.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/reflections-0.9.11.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/rocksdbjni-5.15.10.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/scala-library-2.12.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/scala-reflect-2.12.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/slf4j-api-1.7.25.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/slf4j-log4j12-1.7.25.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/snappy-java-1.1.7.2.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/validation-api-1.1.0.Final.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/zkclient-0.11.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/zookeeper-3.4.13.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/zstd-jni-1.3.8-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:38,220] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:38,220] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:38,220] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:38,220] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:38,221] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:38,221] INFO Client environment:os.version=4.15.0-47-generic (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:38,221] INFO Client environment:user.name=trench (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:38,221] INFO Client environment:user.home=/home/trench (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:38,221] INFO Client environment:user.dir=/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0 (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:38,223] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@29626d54 (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:38,217] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:45:38,230] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-04-15 17:45:38,247] INFO Accepted socket connection from /127.0.0.1:36374 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-04-15 17:45:38,249] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:45:38,255] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:45:38,255] INFO Client attempting to establish new session at /127.0.0.1:36374 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:45:38,261] INFO Established session 0x100000cde360002 with negotiated timeout 6000 for client /127.0.0.1:36374 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:45:38,265] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-04-15 17:45:38,271] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x100000cde360002, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:45:38,274] INFO Accepted socket connection from /127.0.0.1:36376 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-04-15 17:45:38,274] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:45:38,279] INFO Client attempting to establish new session at /127.0.0.1:36376 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:45:38,283] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-04-15 17:45:38,287] INFO Established session 0x100000cde360003 with negotiated timeout 6000 for client /127.0.0.1:36376 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:45:38,306] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x100000cde360003, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:45:38,322] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-04-15 17:45:38,339] INFO Got user-level KeeperException when processing sessionid:0x100000cde360001 type:create cxid:0x1 zxid:0x6 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:45:38,364] INFO Got user-level KeeperException when processing sessionid:0x100000cde360000 type:create cxid:0x2 zxid:0x7 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:45:38,377] INFO Got user-level KeeperException when processing sessionid:0x100000cde360001 type:create cxid:0x2 zxid:0x8 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:45:38,385] INFO Got user-level KeeperException when processing sessionid:0x100000cde360000 type:create cxid:0x3 zxid:0xa txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:45:38,392] INFO Got user-level KeeperException when processing sessionid:0x100000cde360000 type:create cxid:0x4 zxid:0xc txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:45:38,402] INFO Got user-level KeeperException when processing sessionid:0x100000cde360001 type:create cxid:0x6 zxid:0xe txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:45:38,404] INFO Got user-level KeeperException when processing sessionid:0x100000cde360000 type:create cxid:0x5 zxid:0xf txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:45:38,413] INFO Got user-level KeeperException when processing sessionid:0x100000cde360001 type:create cxid:0x8 zxid:0x12 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:45:38,416] INFO Got user-level KeeperException when processing sessionid:0x100000cde360000 type:create cxid:0x7 zxid:0x13 txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:45:38,419] INFO Got user-level KeeperException when processing sessionid:0x100000cde360003 type:create cxid:0x1 zxid:0x14 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:45:38,423] INFO Got user-level KeeperException when processing sessionid:0x100000cde360002 type:create cxid:0x1 zxid:0x15 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:45:38,425] INFO Got user-level KeeperException when processing sessionid:0x100000cde360001 type:create cxid:0x9 zxid:0x16 txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:45:38,437] INFO Got user-level KeeperException when processing sessionid:0x100000cde360001 type:create cxid:0xa zxid:0x18 txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NodeExists for /admin (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:45:38,444] INFO Got user-level KeeperException when processing sessionid:0x100000cde360001 type:create cxid:0xb zxid:0x1a txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:45:38,451] INFO Got user-level KeeperException when processing sessionid:0x100000cde360002 type:create cxid:0x2 zxid:0x1c txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:45:38,452] INFO Got user-level KeeperException when processing sessionid:0x100000cde360001 type:create cxid:0xc zxid:0x1d txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:45:38,453] INFO Got user-level KeeperException when processing sessionid:0x100000cde360003 type:create cxid:0x2 zxid:0x1e txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:45:38,456] INFO Got user-level KeeperException when processing sessionid:0x100000cde360002 type:create cxid:0x3 zxid:0x20 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:45:38,458] INFO Got user-level KeeperException when processing sessionid:0x100000cde360003 type:create cxid:0x3 zxid:0x21 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:45:38,458] INFO Got user-level KeeperException when processing sessionid:0x100000cde360001 type:create cxid:0xd zxid:0x22 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:45:38,461] INFO Got user-level KeeperException when processing sessionid:0x100000cde360002 type:create cxid:0x4 zxid:0x24 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:45:38,462] INFO Got user-level KeeperException when processing sessionid:0x100000cde360003 type:create cxid:0x4 zxid:0x25 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:45:38,465] INFO Got user-level KeeperException when processing sessionid:0x100000cde360001 type:create cxid:0xe zxid:0x27 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:45:38,467] INFO Got user-level KeeperException when processing sessionid:0x100000cde360002 type:create cxid:0x5 zxid:0x28 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:45:38,469] INFO Got user-level KeeperException when processing sessionid:0x100000cde360003 type:create cxid:0x5 zxid:0x29 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:45:38,472] INFO Got user-level KeeperException when processing sessionid:0x100000cde360001 type:create cxid:0xf zxid:0x2b txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:45:38,474] INFO Got user-level KeeperException when processing sessionid:0x100000cde360002 type:create cxid:0x6 zxid:0x2c txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:45:38,476] INFO Got user-level KeeperException when processing sessionid:0x100000cde360003 type:create cxid:0x6 zxid:0x2d txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:45:38,478] INFO Got user-level KeeperException when processing sessionid:0x100000cde360001 type:create cxid:0x10 zxid:0x2e txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:45:38,479] INFO Got user-level KeeperException when processing sessionid:0x100000cde360002 type:create cxid:0x7 zxid:0x30 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:45:38,482] INFO Got user-level KeeperException when processing sessionid:0x100000cde360003 type:create cxid:0x7 zxid:0x31 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:45:38,487] INFO Got user-level KeeperException when processing sessionid:0x100000cde360002 type:create cxid:0x8 zxid:0x33 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:45:38,487] INFO Got user-level KeeperException when processing sessionid:0x100000cde360001 type:create cxid:0x11 zxid:0x34 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:45:38,489] INFO Got user-level KeeperException when processing sessionid:0x100000cde360003 type:create cxid:0x8 zxid:0x35 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:45:38,495] INFO Got user-level KeeperException when processing sessionid:0x100000cde360001 type:create cxid:0x12 zxid:0x37 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:45:38,496] INFO Got user-level KeeperException when processing sessionid:0x100000cde360002 type:create cxid:0x9 zxid:0x38 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:45:38,496] INFO Got user-level KeeperException when processing sessionid:0x100000cde360003 type:create cxid:0x9 zxid:0x39 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:45:38,501] INFO Got user-level KeeperException when processing sessionid:0x100000cde360003 type:create cxid:0xa zxid:0x3a txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:45:38,502] INFO Got user-level KeeperException when processing sessionid:0x100000cde360001 type:create cxid:0x13 zxid:0x3b txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:45:38,505] INFO Got user-level KeeperException when processing sessionid:0x100000cde360002 type:create cxid:0xa zxid:0x3c txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:45:38,511] INFO Got user-level KeeperException when processing sessionid:0x100000cde360003 type:create cxid:0xb zxid:0x3d txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:45:38,513] INFO Got user-level KeeperException when processing sessionid:0x100000cde360002 type:create cxid:0xb zxid:0x3e txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:45:38,516] INFO Got user-level KeeperException when processing sessionid:0x100000cde360003 type:create cxid:0xc zxid:0x3f txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:45:38,521] INFO Got user-level KeeperException when processing sessionid:0x100000cde360003 type:create cxid:0xd zxid:0x40 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:45:38,524] INFO Got user-level KeeperException when processing sessionid:0x100000cde360002 type:create cxid:0xc zxid:0x41 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:45:38,535] INFO Got user-level KeeperException when processing sessionid:0x100000cde360002 type:create cxid:0xd zxid:0x42 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:45:38,836] INFO Got user-level KeeperException when processing sessionid:0x100000cde360001 type:create cxid:0x15 zxid:0x43 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:45:38,863] INFO Cluster ID = 8Gdde9JLQVWUC_mEbInh0w (kafka.server.KafkaServer)
[2019-04-15 17:45:38,869] WARN No meta.properties file under dir /tmp/kafka-logs-1/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-04-15 17:45:38,897] INFO Got user-level KeeperException when processing sessionid:0x100000cde360000 type:create cxid:0x13 zxid:0x46 txntype:-1 reqpath:n/a Error Path:/cluster/id Error:KeeperErrorCode = NodeExists for /cluster/id (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:45:38,907] INFO Got user-level KeeperException when processing sessionid:0x100000cde360003 type:create cxid:0xf zxid:0x47 txntype:-1 reqpath:n/a Error Path:/cluster/id Error:KeeperErrorCode = NodeExists for /cluster/id (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:45:39,062] INFO Cluster ID = 8Gdde9JLQVWUC_mEbInh0w (kafka.server.KafkaServer)
[2019-04-15 17:45:39,079] WARN No meta.properties file under dir /tmp/kafka-logs/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-04-15 17:45:39,085] INFO Cluster ID = 8Gdde9JLQVWUC_mEbInh0w (kafka.server.KafkaServer)
[2019-04-15 17:45:39,104] WARN No meta.properties file under dir /tmp/kafka-logs-3/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-04-15 17:45:39,118] INFO Got user-level KeeperException when processing sessionid:0x100000cde360002 type:create cxid:0xf zxid:0x48 txntype:-1 reqpath:n/a Error Path:/cluster/id Error:KeeperErrorCode = NodeExists for /cluster/id (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:45:39,124] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.2-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.2-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-04-15 17:45:39,167] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.2-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.2-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-04-15 17:45:39,212] INFO Cluster ID = 8Gdde9JLQVWUC_mEbInh0w (kafka.server.KafkaServer)
[2019-04-15 17:45:39,229] WARN No meta.properties file under dir /tmp/kafka-logs-2/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-04-15 17:45:39,246] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:45:39,256] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:45:39,263] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:45:39,306] INFO Log directory /tmp/kafka-logs-1 not found, creating it. (kafka.log.LogManager)
[2019-04-15 17:45:39,321] INFO Loading logs. (kafka.log.LogManager)
[2019-04-15 17:45:39,350] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.2-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.2-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-04-15 17:45:39,359] INFO Logs loading complete in 38 ms. (kafka.log.LogManager)
[2019-04-15 17:45:39,364] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.2-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.2-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-04-15 17:45:39,403] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.2-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.2-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-04-15 17:45:39,418] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-04-15 17:45:39,417] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.2-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.2-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-04-15 17:45:39,440] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-04-15 17:45:39,461] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.2-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.2-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-04-15 17:45:39,492] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:45:39,494] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:45:39,502] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:45:39,511] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.2-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.2-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-04-15 17:45:39,548] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:45:39,551] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:45:39,564] INFO Log directory /tmp/kafka-logs not found, creating it. (kafka.log.LogManager)
[2019-04-15 17:45:39,571] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:45:39,580] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:45:39,586] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:45:39,590] INFO Loading logs. (kafka.log.LogManager)
[2019-04-15 17:45:39,594] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:45:39,608] INFO Logs loading complete in 18 ms. (kafka.log.LogManager)
[2019-04-15 17:45:39,625] INFO Log directory /tmp/kafka-logs-3 not found, creating it. (kafka.log.LogManager)
[2019-04-15 17:45:39,643] INFO Loading logs. (kafka.log.LogManager)
[2019-04-15 17:45:39,666] INFO Logs loading complete in 22 ms. (kafka.log.LogManager)
[2019-04-15 17:45:39,671] INFO Log directory /tmp/kafka-logs-2 not found, creating it. (kafka.log.LogManager)
[2019-04-15 17:45:39,666] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-04-15 17:45:39,689] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-04-15 17:45:39,697] INFO Loading logs. (kafka.log.LogManager)
[2019-04-15 17:45:39,717] INFO Logs loading complete in 20 ms. (kafka.log.LogManager)
[2019-04-15 17:45:39,741] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-04-15 17:45:39,754] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-04-15 17:45:39,784] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-04-15 17:45:39,814] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-04-15 17:45:40,638] INFO Awaiting socket connections on s0.0.0.0:9093. (kafka.network.Acceptor)
[2019-04-15 17:45:40,789] INFO [SocketServer brokerId=1] Created data-plane acceptor and processors for endpoint : EndPoint(null,9093,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-04-15 17:45:40,791] INFO [SocketServer brokerId=1] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-04-15 17:45:40,864] INFO Awaiting socket connections on s0.0.0.0:9094. (kafka.network.Acceptor)
[2019-04-15 17:45:40,895] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:40,902] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:40,926] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:40,927] INFO [ExpirationReaper-1-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:41,004] INFO [SocketServer brokerId=3] Created data-plane acceptor and processors for endpoint : EndPoint(null,9094,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-04-15 17:45:41,007] INFO [SocketServer brokerId=3] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-04-15 17:45:41,040] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-04-15 17:45:41,073] INFO Awaiting socket connections on s0.0.0.0:9092. (kafka.network.Acceptor)
[2019-04-15 17:45:41,082] ERROR [KafkaServer id=2] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.kafka.common.KafkaException: Socket server failed to bind to 0.0.0.0:9094: Address already in use.
	at kafka.network.Acceptor.openServerSocket(SocketServer.scala:573)
	at kafka.network.Acceptor.<init>(SocketServer.scala:451)
	at kafka.network.SocketServer.createAcceptor(SocketServer.scala:245)
	at kafka.network.SocketServer.$anonfun$createDataPlaneAcceptorsAndProcessors$1(SocketServer.scala:215)
	at kafka.network.SocketServer.$anonfun$createDataPlaneAcceptorsAndProcessors$1$adapted(SocketServer.scala:214)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at kafka.network.SocketServer.createDataPlaneAcceptorsAndProcessors(SocketServer.scala:214)
	at kafka.network.SocketServer.startup(SocketServer.scala:114)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:253)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:38)
	at kafka.Kafka$.main(Kafka.scala:75)
	at kafka.Kafka.main(Kafka.scala)
Caused by: java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:67)
	at kafka.network.Acceptor.openServerSocket(SocketServer.scala:569)
	... 13 more
[2019-04-15 17:45:41,109] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)
[2019-04-15 17:45:41,113] INFO [SocketServer brokerId=2] Stopping socket server request processors (kafka.network.SocketServer)
[2019-04-15 17:45:41,128] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-04-15 17:45:41,129] INFO [ExpirationReaper-3-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:41,129] INFO [ExpirationReaper-3-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:41,130] INFO [SocketServer brokerId=2] Stopped socket server request processors (kafka.network.SocketServer)
[2019-04-15 17:45:41,144] INFO Shutting down. (kafka.log.LogManager)
[2019-04-15 17:45:41,148] INFO [ExpirationReaper-3-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:41,148] INFO [ExpirationReaper-3-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:41,176] INFO Stat of the created znode at /brokers/ids/1 is: 73,73,1555314341155,1555314341155,1,0,0,72057649305616385,182,0,73
 (kafka.zk.KafkaZkClient)
[2019-04-15 17:45:41,178] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(shodan,9093,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 73 (kafka.zk.KafkaZkClient)
[2019-04-15 17:45:41,199] WARN No meta.properties file under dir /tmp/kafka-logs-1/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-04-15 17:45:41,221] INFO Shutdown complete. (kafka.log.LogManager)
[2019-04-15 17:45:41,223] INFO [ZooKeeperClient] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-04-15 17:45:41,226] INFO Processed session termination for sessionid: 0x100000cde360002 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:45:41,231] INFO Closed socket connection for client /127.0.0.1:36374 which had sessionid 0x100000cde360002 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-04-15 17:45:41,238] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-04-15 17:45:41,239] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-04-15 17:45:41,239] INFO EventThread shut down for session: 0x100000cde360002 (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:45:41,239] INFO Session: 0x100000cde360002 closed (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:41,242] INFO [ZooKeeperClient] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-04-15 17:45:41,243] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-04-15 17:45:41,243] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:45:41,336] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:41,337] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:41,347] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:41,346] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:41,379] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:41,389] INFO Creating /brokers/ids/3 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-04-15 17:45:41,394] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-04-15 17:45:41,398] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[2019-04-15 17:45:41,425] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:41,425] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:41,455] INFO Stat of the created znode at /brokers/ids/3 is: 77,77,1555314341412,1555314341412,1,0,0,72057649305616387,182,0,77
 (kafka.zk.KafkaZkClient)
[2019-04-15 17:45:41,467] INFO Registered broker 3 at path /brokers/ids/3 with addresses: ArrayBuffer(EndPoint(shodan,9094,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 77 (kafka.zk.KafkaZkClient)
[2019-04-15 17:45:41,478] WARN No meta.properties file under dir /tmp/kafka-logs-3/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-04-15 17:45:41,494] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-04-15 17:45:41,497] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-04-15 17:45:41,503] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-04-15 17:45:41,523] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 18 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-04-15 17:45:41,540] INFO Stat of the created znode at /brokers/ids/0 is: 78,78,1555314341519,1555314341519,1,0,0,72057649305616384,182,0,78
 (kafka.zk.KafkaZkClient)
[2019-04-15 17:45:41,548] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1 (kafka.coordinator.transaction.ProducerIdManager)
[2019-04-15 17:45:41,548] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(shodan,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 78 (kafka.zk.KafkaZkClient)
[2019-04-15 17:45:41,567] WARN No meta.properties file under dir /tmp/kafka-logs/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-04-15 17:45:41,581] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:45:41,582] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:45:41,582] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:45:41,589] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:45:41,589] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:45:41,590] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:45:41,594] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:45:41,595] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:45:41,597] INFO [SocketServer brokerId=2] Shutting down socket server (kafka.network.SocketServer)
[2019-04-15 17:45:41,713] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-04-15 17:45:41,760] INFO [SocketServer brokerId=2] Shutdown completed (kafka.network.SocketServer)
[2019-04-15 17:45:41,784] INFO [KafkaServer id=2] shut down completed (kafka.server.KafkaServer)
[2019-04-15 17:45:41,785] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-04-15 17:45:41,786] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-04-15 17:45:41,798] ERROR Exiting Kafka. (kafka.server.KafkaServerStartable)
[2019-04-15 17:45:41,807] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)
[2019-04-15 17:45:41,831] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:41,871] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:41,882] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:41,898] INFO [ExpirationReaper-3-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:41,929] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-04-15 17:45:41,930] INFO [ExpirationReaper-3-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:41,930] INFO [ExpirationReaper-3-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:41,946] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-04-15 17:45:41,973] INFO [GroupCoordinator 3]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-04-15 17:45:41,980] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 26 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-04-15 17:45:41,983] INFO [GroupCoordinator 3]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-04-15 17:45:42,003] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 14 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-04-15 17:45:42,006] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:1000,blockEndProducerId:1999) by writing to Zk with path version 2 (kafka.coordinator.transaction.ProducerIdManager)
[2019-04-15 17:45:42,053] INFO [ProducerId Manager 3]: Acquired new producerId block (brokerId:3,blockStartProducerId:2000,blockEndProducerId:2999) by writing to Zk with path version 3 (kafka.coordinator.transaction.ProducerIdManager)
[2019-04-15 17:45:42,071] INFO Got user-level KeeperException when processing sessionid:0x100000cde360001 type:multi cxid:0x34 zxid:0x52 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:45:42,074] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-04-15 17:45:42,097] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-04-15 17:45:42,105] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-04-15 17:45:42,105] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-04-15 17:45:42,146] INFO [TransactionCoordinator id=3] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-04-15 17:45:42,148] INFO [SocketServer brokerId=1] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2019-04-15 17:45:42,166] INFO [Transaction Marker Channel Manager 3]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-04-15 17:45:42,167] INFO [TransactionCoordinator id=3] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-04-15 17:45:42,211] INFO Kafka version: 2.2.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-04-15 17:45:42,213] INFO Kafka commitId: 05fcfde8f69b0349 (org.apache.kafka.common.utils.AppInfoParser)
[2019-04-15 17:45:42,222] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2019-04-15 17:45:42,407] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-04-15 17:45:42,445] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-04-15 17:45:42,459] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2019-04-15 17:45:42,468] INFO Kafka version: 2.2.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-04-15 17:45:42,468] INFO Kafka commitId: 05fcfde8f69b0349 (org.apache.kafka.common.utils.AppInfoParser)
[2019-04-15 17:45:42,471] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2019-04-15 17:45:42,503] INFO [SocketServer brokerId=3] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2019-04-15 17:45:42,536] INFO Kafka version: 2.2.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-04-15 17:45:42,536] INFO Kafka commitId: 05fcfde8f69b0349 (org.apache.kafka.common.utils.AppInfoParser)
[2019-04-15 17:45:42,545] INFO [KafkaServer id=3] started (kafka.server.KafkaServer)
[2019-04-15 17:45:43,798] INFO [Admin Manager on Broker 1]: Error processing create topic request for topic orderer with arguments (numPartitions=1, replicationFactor=4, replicasAssignments={}, configs={}) (kafka.server.AdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 4 larger than available brokers: 3.
[2019-04-15 17:45:48,933] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-04-15 17:45:48,935] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2019-04-15 17:45:48,938] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2019-04-15 17:45:48,969] INFO [KafkaServer id=0] Controlled shutdown succeeded (kafka.server.KafkaServer)
[2019-04-15 17:45:48,975] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-04-15 17:45:48,976] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-04-15 17:45:48,976] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-04-15 17:45:48,980] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2019-04-15 17:45:49,005] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2019-04-15 17:45:49,008] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2019-04-15 17:45:49,011] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2019-04-15 17:45:49,016] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2019-04-15 17:45:49,019] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:49,039] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:49,039] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:49,043] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-04-15 17:45:49,044] INFO [ProducerId Manager 0]: Shutdown complete: last producerId assigned 1000 (kafka.coordinator.transaction.ProducerIdManager)
[2019-04-15 17:45:49,046] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2019-04-15 17:45:49,046] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-04-15 17:45:49,052] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-04-15 17:45:49,052] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-04-15 17:45:49,053] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-04-15 17:45:49,055] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2019-04-15 17:45:49,056] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:49,092] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:49,092] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:49,093] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:49,286] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:49,286] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:49,288] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2019-04-15 17:45:49,292] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2019-04-15 17:45:49,293] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-04-15 17:45:49,293] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-04-15 17:45:49,293] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-04-15 17:45:49,295] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2019-04-15 17:45:49,298] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2019-04-15 17:45:49,299] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2019-04-15 17:45:49,300] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2019-04-15 17:45:49,300] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:49,360] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:49,360] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:49,361] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:49,547] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:49,547] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:49,547] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:49,553] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:49,553] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:49,553] INFO [ExpirationReaper-0-ElectPreferredLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:49,753] INFO [ExpirationReaper-0-ElectPreferredLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:49,753] INFO [ExpirationReaper-0-ElectPreferredLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:49,764] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2019-04-15 17:45:49,766] INFO Shutting down. (kafka.log.LogManager)
[2019-04-15 17:45:49,808] INFO Shutdown complete. (kafka.log.LogManager)
[2019-04-15 17:45:49,821] INFO [ZooKeeperClient] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-04-15 17:45:49,822] INFO Processed session termination for sessionid: 0x100000cde360000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:45:49,830] INFO Closed socket connection for client /127.0.0.1:36370 which had sessionid 0x100000cde360000 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-04-15 17:45:49,831] INFO Session: 0x100000cde360000 closed (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:49,831] INFO EventThread shut down for session: 0x100000cde360000 (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:45:49,835] INFO [ZooKeeperClient] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-04-15 17:45:49,837] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:45:50,494] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:45:50,494] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:45:50,495] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:45:50,498] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:45:50,498] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:45:50,499] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:45:50,504] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:45:50,504] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:45:50,508] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer)
[2019-04-15 17:45:50,549] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-04-15 17:45:50,550] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer)
[2019-04-15 17:45:50,551] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2019-04-15 17:45:50,557] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2019-04-15 17:45:50,557] INFO [KafkaServer id=1] Starting controlled shutdown (kafka.server.KafkaServer)
[2019-04-15 17:45:50,577] INFO [KafkaServer id=1] Controlled shutdown succeeded (kafka.server.KafkaServer)
[2019-04-15 17:45:50,582] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-04-15 17:45:50,583] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-04-15 17:45:50,583] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-04-15 17:45:50,585] INFO [SocketServer brokerId=1] Stopping socket server request processors (kafka.network.SocketServer)
[2019-04-15 17:45:50,598] INFO [SocketServer brokerId=1] Stopped socket server request processors (kafka.network.SocketServer)
[2019-04-15 17:45:50,600] INFO [data-plane Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
[2019-04-15 17:45:50,603] INFO [data-plane Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2019-04-15 17:45:50,606] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
[2019-04-15 17:45:50,608] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:50,804] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:50,804] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:50,811] INFO [TransactionCoordinator id=1] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-04-15 17:45:50,813] INFO [ProducerId Manager 1]: Shutdown complete: last producerId assigned 0 (kafka.coordinator.transaction.ProducerIdManager)
[2019-04-15 17:45:50,814] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2019-04-15 17:45:50,814] INFO [Transaction Marker Channel Manager 1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-04-15 17:45:50,818] INFO [Transaction Marker Channel Manager 1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-04-15 17:45:50,818] INFO [Transaction Marker Channel Manager 1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-04-15 17:45:50,819] INFO [TransactionCoordinator id=1] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-04-15 17:45:50,821] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2019-04-15 17:45:50,821] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:50,834] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:50,834] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:50,835] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:51,034] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:51,034] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:51,036] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2019-04-15 17:45:51,039] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
[2019-04-15 17:45:51,040] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-04-15 17:45:51,040] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-04-15 17:45:51,041] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-04-15 17:45:51,043] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2019-04-15 17:45:51,046] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2019-04-15 17:45:51,047] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2019-04-15 17:45:51,047] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2019-04-15 17:45:51,047] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:51,101] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-04-15 17:45:51,137] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:51,137] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:51,137] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:51,316] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:51,316] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:51,316] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:51,330] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:51,330] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:51,331] INFO [ExpirationReaper-1-ElectPreferredLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:51,343] INFO [ExpirationReaper-1-ElectPreferredLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:51,343] INFO [ExpirationReaper-1-ElectPreferredLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:51,353] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
[2019-04-15 17:45:51,355] INFO Shutting down. (kafka.log.LogManager)
[2019-04-15 17:45:51,393] INFO Shutdown complete. (kafka.log.LogManager)
[2019-04-15 17:45:51,405] INFO [ZooKeeperClient] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-04-15 17:45:51,407] INFO Processed session termination for sessionid: 0x100000cde360001 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:45:51,412] INFO Session: 0x100000cde360001 closed (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:51,412] INFO EventThread shut down for session: 0x100000cde360001 (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:45:51,413] INFO Closed socket connection for client /127.0.0.1:36372 which had sessionid 0x100000cde360001 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-04-15 17:45:51,413] INFO [ZooKeeperClient] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-04-15 17:45:51,414] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:45:51,542] INFO Got user-level KeeperException when processing sessionid:0x100000cde360003 type:multi cxid:0x34 zxid:0x56 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:45:52,249] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:45:52,249] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:45:52,250] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:45:52,258] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:45:52,258] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:45:52,259] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:45:52,265] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:45:52,265] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:45:52,266] INFO [SocketServer brokerId=1] Shutting down socket server (kafka.network.SocketServer)
[2019-04-15 17:45:52,306] INFO [SocketServer brokerId=1] Shutdown completed (kafka.network.SocketServer)
[2019-04-15 17:45:52,310] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
[2019-04-15 17:45:52,737] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-04-15 17:45:52,740] INFO [KafkaServer id=3] shutting down (kafka.server.KafkaServer)
[2019-04-15 17:45:52,744] INFO [KafkaServer id=3] Starting controlled shutdown (kafka.server.KafkaServer)
[2019-04-15 17:45:52,767] INFO [KafkaServer id=3] Controlled shutdown succeeded (kafka.server.KafkaServer)
[2019-04-15 17:45:52,773] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-04-15 17:45:52,774] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-04-15 17:45:52,774] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-04-15 17:45:52,775] INFO [SocketServer brokerId=3] Stopping socket server request processors (kafka.network.SocketServer)
[2019-04-15 17:45:52,795] INFO [SocketServer brokerId=3] Stopped socket server request processors (kafka.network.SocketServer)
[2019-04-15 17:45:52,797] INFO [data-plane Kafka Request Handler on Broker 3], shutting down (kafka.server.KafkaRequestHandlerPool)
[2019-04-15 17:45:52,800] INFO [data-plane Kafka Request Handler on Broker 3], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2019-04-15 17:45:52,804] INFO [KafkaApi-3] Shutdown complete. (kafka.server.KafkaApis)
[2019-04-15 17:45:52,805] INFO [ExpirationReaper-3-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:52,907] INFO [ExpirationReaper-3-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:52,907] INFO [ExpirationReaper-3-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:52,913] INFO [TransactionCoordinator id=3] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-04-15 17:45:52,916] INFO [ProducerId Manager 3]: Shutdown complete: last producerId assigned 2000 (kafka.coordinator.transaction.ProducerIdManager)
[2019-04-15 17:45:52,917] INFO [Transaction State Manager 3]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2019-04-15 17:45:52,918] INFO [Transaction Marker Channel Manager 3]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-04-15 17:45:52,922] INFO [Transaction Marker Channel Manager 3]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-04-15 17:45:52,922] INFO [Transaction Marker Channel Manager 3]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-04-15 17:45:52,924] INFO [TransactionCoordinator id=3] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-04-15 17:45:52,925] INFO [GroupCoordinator 3]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2019-04-15 17:45:52,926] INFO [ExpirationReaper-3-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:52,944] INFO [ExpirationReaper-3-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:52,944] INFO [ExpirationReaper-3-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:52,944] INFO [ExpirationReaper-3-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:53,143] INFO [ExpirationReaper-3-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:53,143] INFO [ExpirationReaper-3-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:53,147] INFO [GroupCoordinator 3]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2019-04-15 17:45:53,151] INFO [ReplicaManager broker=3] Shutting down (kafka.server.ReplicaManager)
[2019-04-15 17:45:53,152] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-04-15 17:45:53,153] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-04-15 17:45:53,153] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-04-15 17:45:53,154] INFO [ReplicaFetcherManager on broker 3] shutting down (kafka.server.ReplicaFetcherManager)
[2019-04-15 17:45:53,157] INFO [ReplicaFetcherManager on broker 3] shutdown completed (kafka.server.ReplicaFetcherManager)
[2019-04-15 17:45:53,157] INFO [ReplicaAlterLogDirsManager on broker 3] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2019-04-15 17:45:53,158] INFO [ReplicaAlterLogDirsManager on broker 3] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2019-04-15 17:45:53,158] INFO [ExpirationReaper-3-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:53,342] INFO [ExpirationReaper-3-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:53,342] INFO [ExpirationReaper-3-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:53,343] INFO [ExpirationReaper-3-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:53,543] INFO [ExpirationReaper-3-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:53,543] INFO [ExpirationReaper-3-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:53,544] INFO [ExpirationReaper-3-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:53,559] INFO [ExpirationReaper-3-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:53,559] INFO [ExpirationReaper-3-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:53,559] INFO [ExpirationReaper-3-ElectPreferredLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:53,564] INFO [ExpirationReaper-3-ElectPreferredLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:53,564] INFO [ExpirationReaper-3-ElectPreferredLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:45:53,572] INFO [ReplicaManager broker=3] Shut down completely (kafka.server.ReplicaManager)
[2019-04-15 17:45:53,574] INFO Shutting down. (kafka.log.LogManager)
[2019-04-15 17:45:53,608] INFO Shutdown complete. (kafka.log.LogManager)
[2019-04-15 17:45:53,622] INFO [ZooKeeperClient] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-04-15 17:45:53,624] INFO Processed session termination for sessionid: 0x100000cde360003 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:45:53,631] INFO Closed socket connection for client /127.0.0.1:36376 which had sessionid 0x100000cde360003 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-04-15 17:45:53,631] INFO Session: 0x100000cde360003 closed (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:45:53,631] INFO EventThread shut down for session: 0x100000cde360003 (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:45:53,633] INFO [ZooKeeperClient] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-04-15 17:45:53,634] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:45:54,551] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:45:54,551] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:45:54,551] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:45:54,553] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:45:54,553] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:45:54,553] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:45:54,575] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:45:54,575] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:45:54,580] INFO [SocketServer brokerId=3] Shutting down socket server (kafka.network.SocketServer)
[2019-04-15 17:45:54,630] INFO [SocketServer brokerId=3] Shutdown completed (kafka.network.SocketServer)
[2019-04-15 17:45:54,636] INFO [KafkaServer id=3] shut down completed (kafka.server.KafkaServer)
[2019-04-15 17:46:25,426] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-04-15 17:46:25,431] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-04-15 17:46:25,431] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-04-15 17:46:25,434] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-04-15 17:46:25,434] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-04-15 17:46:25,458] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-04-15 17:46:25,458] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-04-15 17:46:25,472] INFO Server environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:46:25,472] INFO Server environment:host.name=shodan (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:46:25,472] INFO Server environment:java.version=1.8.0_181 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:46:25,472] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:46:25,472] INFO Server environment:java.home=/usr/lib/jvm/java-8-oracle/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:46:25,472] INFO Server environment:java.class.path=/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/activation-1.1.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/aopalliance-repackaged-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/argparse4j-0.7.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/audience-annotations-0.5.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/commons-lang3-3.8.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-api-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-basic-auth-extension-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-file-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-json-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-runtime-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-transforms-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/guava-20.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/hk2-api-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/hk2-locator-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/hk2-utils-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-annotations-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-core-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-databind-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-datatype-jdk8-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-jaxrs-base-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-jaxrs-json-provider-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-module-jaxb-annotations-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javassist-3.22.0-CR2.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.annotation-api-1.2.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.inject-1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.inject-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.ws.rs-api-2.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jaxb-api-2.3.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-client-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-common-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-container-servlet-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-container-servlet-core-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-hk2-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-media-jaxb-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-server-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-client-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-continuation-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-http-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-io-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-security-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-server-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-servlet-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-servlets-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-util-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jopt-simple-5.0.4.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka_2.12-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka_2.12-2.2.0-sources.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-clients-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-log4j-appender-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-streams-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-streams-examples-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-streams-scala_2.12-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-streams-test-utils-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-tools-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/log4j-1.2.17.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/lz4-java-1.5.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/maven-artifact-3.6.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/metrics-core-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/plexus-utils-3.1.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/reflections-0.9.11.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/rocksdbjni-5.15.10.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/scala-library-2.12.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/scala-reflect-2.12.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/slf4j-api-1.7.25.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/slf4j-log4j12-1.7.25.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/snappy-java-1.1.7.2.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/validation-api-1.1.0.Final.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/zkclient-0.11.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/zookeeper-3.4.13.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/zstd-jni-1.3.8-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:46:25,473] INFO Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:46:25,474] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:46:25,474] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:46:25,474] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:46:25,474] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:46:25,474] INFO Server environment:os.version=4.15.0-47-generic (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:46:25,474] INFO Server environment:user.name=trench (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:46:25,474] INFO Server environment:user.home=/home/trench (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:46:25,474] INFO Server environment:user.dir=/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:46:25,485] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:46:25,485] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:46:25,485] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:46:25,495] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-04-15 17:46:25,500] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-04-15 17:46:29,401] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-04-15 17:46:29,473] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-04-15 17:46:29,607] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-04-15 17:46:29,665] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-04-15 17:46:30,795] INFO starting (kafka.server.KafkaServer)
[2019-04-15 17:46:30,800] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-04-15 17:46:30,827] INFO starting (kafka.server.KafkaServer)
[2019-04-15 17:46:30,828] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-04-15 17:46:30,876] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-04-15 17:46:30,886] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:30,886] INFO Client environment:host.name=shodan (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:30,886] INFO Client environment:java.version=1.8.0_181 (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:30,886] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:30,886] INFO Client environment:java.home=/usr/lib/jvm/java-8-oracle/jre (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:30,886] INFO Client environment:java.class.path=/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/activation-1.1.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/aopalliance-repackaged-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/argparse4j-0.7.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/audience-annotations-0.5.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/commons-lang3-3.8.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-api-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-basic-auth-extension-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-file-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-json-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-runtime-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-transforms-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/guava-20.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/hk2-api-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/hk2-locator-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/hk2-utils-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-annotations-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-core-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-databind-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-datatype-jdk8-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-jaxrs-base-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-jaxrs-json-provider-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-module-jaxb-annotations-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javassist-3.22.0-CR2.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.annotation-api-1.2.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.inject-1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.inject-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.ws.rs-api-2.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jaxb-api-2.3.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-client-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-common-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-container-servlet-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-container-servlet-core-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-hk2-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-media-jaxb-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-server-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-client-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-continuation-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-http-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-io-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-security-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-server-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-servlet-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-servlets-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-util-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jopt-simple-5.0.4.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka_2.12-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka_2.12-2.2.0-sources.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-clients-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-log4j-appender-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-streams-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-streams-examples-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-streams-scala_2.12-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-streams-test-utils-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-tools-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/log4j-1.2.17.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/lz4-java-1.5.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/maven-artifact-3.6.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/metrics-core-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/plexus-utils-3.1.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/reflections-0.9.11.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/rocksdbjni-5.15.10.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/scala-library-2.12.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/scala-reflect-2.12.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/slf4j-api-1.7.25.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/slf4j-log4j12-1.7.25.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/snappy-java-1.1.7.2.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/validation-api-1.1.0.Final.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/zkclient-0.11.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/zookeeper-3.4.13.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/zstd-jni-1.3.8-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:30,888] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:30,888] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:30,888] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:30,888] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:30,888] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:30,888] INFO Client environment:os.version=4.15.0-47-generic (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:30,888] INFO Client environment:user.name=trench (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:30,889] INFO Client environment:user.home=/home/trench (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:30,889] INFO Client environment:user.dir=/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0 (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:30,892] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-04-15 17:46:30,893] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@29626d54 (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:30,906] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:30,907] INFO Client environment:host.name=shodan (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:30,907] INFO Client environment:java.version=1.8.0_181 (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:30,908] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:30,909] INFO Client environment:java.home=/usr/lib/jvm/java-8-oracle/jre (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:30,910] INFO Client environment:java.class.path=/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/activation-1.1.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/aopalliance-repackaged-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/argparse4j-0.7.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/audience-annotations-0.5.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/commons-lang3-3.8.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-api-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-basic-auth-extension-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-file-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-json-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-runtime-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-transforms-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/guava-20.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/hk2-api-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/hk2-locator-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/hk2-utils-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-annotations-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-core-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-databind-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-datatype-jdk8-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-jaxrs-base-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-jaxrs-json-provider-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-module-jaxb-annotations-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javassist-3.22.0-CR2.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.annotation-api-1.2.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.inject-1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.inject-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.ws.rs-api-2.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jaxb-api-2.3.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-client-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-common-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-container-servlet-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-container-servlet-core-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-hk2-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-media-jaxb-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-server-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-client-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-continuation-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-http-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-io-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-security-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-server-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-servlet-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-servlets-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-util-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jopt-simple-5.0.4.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka_2.12-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka_2.12-2.2.0-sources.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-clients-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-log4j-appender-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-streams-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-streams-examples-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-streams-scala_2.12-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-streams-test-utils-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-tools-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/log4j-1.2.17.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/lz4-java-1.5.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/maven-artifact-3.6.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/metrics-core-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/plexus-utils-3.1.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/reflections-0.9.11.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/rocksdbjni-5.15.10.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/scala-library-2.12.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/scala-reflect-2.12.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/slf4j-api-1.7.25.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/slf4j-log4j12-1.7.25.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/snappy-java-1.1.7.2.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/validation-api-1.1.0.Final.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/zkclient-0.11.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/zookeeper-3.4.13.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/zstd-jni-1.3.8-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:30,915] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:30,915] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:30,915] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:30,915] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:30,916] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:30,916] INFO Client environment:os.version=4.15.0-47-generic (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:30,916] INFO Client environment:user.name=trench (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:30,916] INFO Client environment:user.home=/home/trench (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:30,916] INFO Client environment:user.dir=/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0 (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:30,920] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@29626d54 (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:30,954] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:46:30,964] INFO Accepted socket connection from /127.0.0.1:36396 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-04-15 17:46:30,968] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:46:30,973] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-04-15 17:46:30,972] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-04-15 17:46:30,983] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:46:30,996] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:46:31,001] INFO Client attempting to establish new session at /127.0.0.1:36396 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:46:31,010] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-04-15 17:46:31,020] INFO Accepted socket connection from /127.0.0.1:36398 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-04-15 17:46:31,023] INFO Client attempting to establish new session at /127.0.0.1:36398 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:46:31,050] INFO Established session 0x100000daca00000 with negotiated timeout 6000 for client /127.0.0.1:36396 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:46:31,053] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x100000daca00000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:46:31,054] INFO starting (kafka.server.KafkaServer)
[2019-04-15 17:46:31,056] INFO Established session 0x100000daca00001 with negotiated timeout 6000 for client /127.0.0.1:36398 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:46:31,059] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x100000daca00001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:46:31,060] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-04-15 17:46:31,064] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-04-15 17:46:31,074] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-04-15 17:46:31,120] INFO starting (kafka.server.KafkaServer)
[2019-04-15 17:46:31,122] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-04-15 17:46:31,146] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-04-15 17:46:31,155] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:31,155] INFO Client environment:host.name=shodan (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:31,155] INFO Client environment:java.version=1.8.0_181 (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:31,155] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:31,158] INFO Client environment:java.home=/usr/lib/jvm/java-8-oracle/jre (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:31,159] INFO Client environment:java.class.path=/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/activation-1.1.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/aopalliance-repackaged-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/argparse4j-0.7.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/audience-annotations-0.5.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/commons-lang3-3.8.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-api-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-basic-auth-extension-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-file-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-json-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-runtime-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-transforms-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/guava-20.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/hk2-api-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/hk2-locator-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/hk2-utils-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-annotations-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-core-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-databind-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-datatype-jdk8-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-jaxrs-base-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-jaxrs-json-provider-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-module-jaxb-annotations-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javassist-3.22.0-CR2.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.annotation-api-1.2.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.inject-1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.inject-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.ws.rs-api-2.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jaxb-api-2.3.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-client-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-common-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-container-servlet-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-container-servlet-core-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-hk2-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-media-jaxb-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-server-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-client-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-continuation-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-http-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-io-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-security-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-server-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-servlet-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-servlets-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-util-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jopt-simple-5.0.4.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka_2.12-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka_2.12-2.2.0-sources.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-clients-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-log4j-appender-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-streams-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-streams-examples-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-streams-scala_2.12-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-streams-test-utils-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-tools-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/log4j-1.2.17.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/lz4-java-1.5.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/maven-artifact-3.6.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/metrics-core-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/plexus-utils-3.1.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/reflections-0.9.11.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/rocksdbjni-5.15.10.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/scala-library-2.12.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/scala-reflect-2.12.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/slf4j-api-1.7.25.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/slf4j-log4j12-1.7.25.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/snappy-java-1.1.7.2.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/validation-api-1.1.0.Final.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/zkclient-0.11.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/zookeeper-3.4.13.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/zstd-jni-1.3.8-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:31,160] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:31,161] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:31,161] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:31,161] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:31,161] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:31,161] INFO Client environment:os.version=4.15.0-47-generic (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:31,161] INFO Client environment:user.name=trench (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:31,161] INFO Client environment:user.home=/home/trench (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:31,161] INFO Client environment:user.dir=/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0 (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:31,164] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@29626d54 (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:31,188] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:46:31,196] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-04-15 17:46:31,198] INFO Accepted socket connection from /127.0.0.1:36400 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-04-15 17:46:31,199] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:46:31,208] INFO Client attempting to establish new session at /127.0.0.1:36400 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:46:31,211] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-04-15 17:46:31,213] INFO Established session 0x100000daca00002 with negotiated timeout 6000 for client /127.0.0.1:36400 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:46:31,219] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x100000daca00002, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:46:31,228] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:31,228] INFO Client environment:host.name=shodan (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:31,228] INFO Client environment:java.version=1.8.0_181 (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:31,228] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:31,229] INFO Client environment:java.home=/usr/lib/jvm/java-8-oracle/jre (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:31,229] INFO Got user-level KeeperException when processing sessionid:0x100000daca00000 type:create cxid:0x2 zxid:0x5 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:46:31,229] INFO Client environment:java.class.path=/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/activation-1.1.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/aopalliance-repackaged-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/argparse4j-0.7.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/audience-annotations-0.5.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/commons-lang3-3.8.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-api-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-basic-auth-extension-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-file-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-json-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-runtime-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/connect-transforms-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/guava-20.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/hk2-api-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/hk2-locator-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/hk2-utils-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-annotations-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-core-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-databind-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-datatype-jdk8-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-jaxrs-base-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-jaxrs-json-provider-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jackson-module-jaxb-annotations-2.9.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javassist-3.22.0-CR2.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.annotation-api-1.2.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.inject-1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.inject-2.5.0-b42.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/javax.ws.rs-api-2.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jaxb-api-2.3.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-client-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-common-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-container-servlet-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-container-servlet-core-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-hk2-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-media-jaxb-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jersey-server-2.27.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-client-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-continuation-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-http-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-io-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-security-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-server-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-servlet-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-servlets-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jetty-util-9.4.14.v20181114.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/jopt-simple-5.0.4.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka_2.12-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka_2.12-2.2.0-sources.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-clients-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-log4j-appender-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-streams-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-streams-examples-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-streams-scala_2.12-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-streams-test-utils-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/kafka-tools-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/log4j-1.2.17.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/lz4-java-1.5.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/maven-artifact-3.6.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/metrics-core-2.2.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/plexus-utils-3.1.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/reflections-0.9.11.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/rocksdbjni-5.15.10.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/scala-library-2.12.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/scala-reflect-2.12.8.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/slf4j-api-1.7.25.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/slf4j-log4j12-1.7.25.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/snappy-java-1.1.7.2.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/validation-api-1.1.0.Final.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/zkclient-0.11.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/zookeeper-3.4.13.jar:/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0/bin/../libs/zstd-jni-1.3.8-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:31,230] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:31,230] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:31,230] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:31,230] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:31,230] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:31,230] INFO Client environment:os.version=4.15.0-47-generic (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:31,230] INFO Client environment:user.name=trench (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:31,231] INFO Client environment:user.home=/home/trench (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:31,231] INFO Client environment:user.dir=/home/trench/fabric-dev-servers/productchain-network/kafka_2.12-2.2.0 (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:31,231] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-04-15 17:46:31,233] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@29626d54 (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:31,235] INFO Got user-level KeeperException when processing sessionid:0x100000daca00001 type:create cxid:0x1 zxid:0x6 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:46:31,258] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-04-15 17:46:31,262] INFO Got user-level KeeperException when processing sessionid:0x100000daca00001 type:create cxid:0x2 zxid:0xa txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:46:31,264] INFO Got user-level KeeperException when processing sessionid:0x100000daca00000 type:create cxid:0x6 zxid:0xb txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:46:31,262] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:46:31,268] INFO Got user-level KeeperException when processing sessionid:0x100000daca00001 type:create cxid:0x3 zxid:0xc txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:46:31,276] INFO Got user-level KeeperException when processing sessionid:0x100000daca00000 type:create cxid:0x8 zxid:0xf txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:46:31,277] INFO Accepted socket connection from /127.0.0.1:36402 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-04-15 17:46:31,279] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:46:31,280] INFO Got user-level KeeperException when processing sessionid:0x100000daca00001 type:create cxid:0x5 zxid:0x10 txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:46:31,282] INFO Got user-level KeeperException when processing sessionid:0x100000daca00000 type:create cxid:0x9 zxid:0x11 txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:46:31,285] INFO Client attempting to establish new session at /127.0.0.1:36402 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:46:31,288] INFO Got user-level KeeperException when processing sessionid:0x100000daca00000 type:create cxid:0xa zxid:0x14 txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NodeExists for /admin (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:46:31,291] INFO Established session 0x100000daca00003 with negotiated timeout 6000 for client /127.0.0.1:36402 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-04-15 17:46:31,296] INFO Got user-level KeeperException when processing sessionid:0x100000daca00000 type:create cxid:0xb zxid:0x16 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:46:31,308] INFO Got user-level KeeperException when processing sessionid:0x100000daca00000 type:create cxid:0xc zxid:0x18 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:46:31,300] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x100000daca00003, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:46:31,314] INFO Got user-level KeeperException when processing sessionid:0x100000daca00000 type:create cxid:0xd zxid:0x1a txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:46:31,321] INFO Got user-level KeeperException when processing sessionid:0x100000daca00000 type:create cxid:0xe zxid:0x1c txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:46:31,327] INFO Got user-level KeeperException when processing sessionid:0x100000daca00000 type:create cxid:0xf zxid:0x1e txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:46:31,329] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-04-15 17:46:31,336] INFO Got user-level KeeperException when processing sessionid:0x100000daca00000 type:create cxid:0x10 zxid:0x20 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:46:31,345] INFO Got user-level KeeperException when processing sessionid:0x100000daca00000 type:create cxid:0x11 zxid:0x22 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:46:31,347] INFO Got user-level KeeperException when processing sessionid:0x100000daca00002 type:create cxid:0x1 zxid:0x24 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:46:31,350] INFO Got user-level KeeperException when processing sessionid:0x100000daca00000 type:create cxid:0x12 zxid:0x25 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:46:31,363] INFO Got user-level KeeperException when processing sessionid:0x100000daca00000 type:create cxid:0x13 zxid:0x27 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:46:31,373] INFO Got user-level KeeperException when processing sessionid:0x100000daca00002 type:create cxid:0x2 zxid:0x28 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:46:31,386] INFO Got user-level KeeperException when processing sessionid:0x100000daca00002 type:create cxid:0x3 zxid:0x29 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:46:31,399] INFO Got user-level KeeperException when processing sessionid:0x100000daca00002 type:create cxid:0x4 zxid:0x2a txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:46:31,404] INFO Got user-level KeeperException when processing sessionid:0x100000daca00002 type:create cxid:0x5 zxid:0x2b txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:46:31,408] INFO Got user-level KeeperException when processing sessionid:0x100000daca00002 type:create cxid:0x6 zxid:0x2c txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:46:31,413] INFO Got user-level KeeperException when processing sessionid:0x100000daca00002 type:create cxid:0x7 zxid:0x2d txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:46:31,417] INFO Got user-level KeeperException when processing sessionid:0x100000daca00002 type:create cxid:0x8 zxid:0x2e txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:46:31,422] INFO Got user-level KeeperException when processing sessionid:0x100000daca00002 type:create cxid:0x9 zxid:0x2f txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:46:31,427] INFO Got user-level KeeperException when processing sessionid:0x100000daca00002 type:create cxid:0xa zxid:0x30 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:46:31,434] INFO Got user-level KeeperException when processing sessionid:0x100000daca00003 type:create cxid:0x1 zxid:0x31 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:46:31,434] INFO Got user-level KeeperException when processing sessionid:0x100000daca00002 type:create cxid:0xb zxid:0x32 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:46:31,451] INFO Got user-level KeeperException when processing sessionid:0x100000daca00002 type:create cxid:0xc zxid:0x33 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:46:31,460] INFO Got user-level KeeperException when processing sessionid:0x100000daca00002 type:create cxid:0xd zxid:0x34 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:46:31,462] INFO Got user-level KeeperException when processing sessionid:0x100000daca00003 type:create cxid:0x2 zxid:0x35 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:46:31,478] INFO Got user-level KeeperException when processing sessionid:0x100000daca00003 type:create cxid:0x3 zxid:0x36 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:46:31,484] INFO Got user-level KeeperException when processing sessionid:0x100000daca00003 type:create cxid:0x4 zxid:0x37 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:46:31,492] INFO Got user-level KeeperException when processing sessionid:0x100000daca00003 type:create cxid:0x5 zxid:0x38 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:46:31,497] INFO Got user-level KeeperException when processing sessionid:0x100000daca00003 type:create cxid:0x6 zxid:0x39 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:46:31,502] INFO Got user-level KeeperException when processing sessionid:0x100000daca00003 type:create cxid:0x7 zxid:0x3a txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:46:31,506] INFO Got user-level KeeperException when processing sessionid:0x100000daca00003 type:create cxid:0x8 zxid:0x3b txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:46:31,511] INFO Got user-level KeeperException when processing sessionid:0x100000daca00003 type:create cxid:0x9 zxid:0x3c txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:46:31,517] INFO Got user-level KeeperException when processing sessionid:0x100000daca00003 type:create cxid:0xa zxid:0x3d txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:46:31,526] INFO Got user-level KeeperException when processing sessionid:0x100000daca00003 type:create cxid:0xb zxid:0x3e txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:46:31,530] INFO Got user-level KeeperException when processing sessionid:0x100000daca00003 type:create cxid:0xc zxid:0x3f txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:46:31,542] INFO Got user-level KeeperException when processing sessionid:0x100000daca00003 type:create cxid:0xd zxid:0x40 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:46:31,804] INFO Got user-level KeeperException when processing sessionid:0x100000daca00001 type:create cxid:0x11 zxid:0x41 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:46:31,824] INFO Got user-level KeeperException when processing sessionid:0x100000daca00000 type:create cxid:0x15 zxid:0x42 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:46:31,855] INFO Cluster ID = 9kMGIvMbTiiN7YO2d7yyKw (kafka.server.KafkaServer)
[2019-04-15 17:46:31,867] INFO Got user-level KeeperException when processing sessionid:0x100000daca00000 type:create cxid:0x16 zxid:0x45 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NodeExists for /cluster (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:46:31,871] INFO Got user-level KeeperException when processing sessionid:0x100000daca00002 type:create cxid:0xf zxid:0x46 txntype:-1 reqpath:n/a Error Path:/cluster/id Error:KeeperErrorCode = NodeExists for /cluster/id (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:46:31,871] INFO Got user-level KeeperException when processing sessionid:0x100000daca00000 type:create cxid:0x17 zxid:0x47 txntype:-1 reqpath:n/a Error Path:/cluster/id Error:KeeperErrorCode = NodeExists for /cluster/id (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:46:31,935] INFO Cluster ID = 9kMGIvMbTiiN7YO2d7yyKw (kafka.server.KafkaServer)
[2019-04-15 17:46:31,941] WARN No meta.properties file under dir /tmp/kafka-logs-2/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-04-15 17:46:31,993] INFO Cluster ID = 9kMGIvMbTiiN7YO2d7yyKw (kafka.server.KafkaServer)
[2019-04-15 17:46:32,021] INFO Got user-level KeeperException when processing sessionid:0x100000daca00003 type:create cxid:0xf zxid:0x48 txntype:-1 reqpath:n/a Error Path:/cluster/id Error:KeeperErrorCode = NodeExists for /cluster/id (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:46:32,100] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.2-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.2-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-04-15 17:46:32,138] INFO Cluster ID = 9kMGIvMbTiiN7YO2d7yyKw (kafka.server.KafkaServer)
[2019-04-15 17:46:32,156] WARN No meta.properties file under dir /tmp/kafka-logs/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-04-15 17:46:32,145] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.2-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.2-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-04-15 17:46:32,210] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.2-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.2-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-04-15 17:46:32,255] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:46:32,256] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.2-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.2-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-04-15 17:46:32,267] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:46:32,276] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:46:32,298] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.2-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.2-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-04-15 17:46:32,332] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.2-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.2-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-04-15 17:46:32,348] INFO Loading logs. (kafka.log.LogManager)
[2019-04-15 17:46:32,354] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.2-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.2-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-04-15 17:46:32,373] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:46:32,382] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:46:32,376] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.2-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.2-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-04-15 17:46:32,384] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:46:32,394] INFO Logs loading complete in 46 ms. (kafka.log.LogManager)
[2019-04-15 17:46:32,444] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:46:32,447] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:46:32,449] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:46:32,453] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-04-15 17:46:32,457] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:46:32,460] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:46:32,466] INFO Loading logs. (kafka.log.LogManager)
[2019-04-15 17:46:32,472] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:46:32,480] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-04-15 17:46:32,492] INFO Logs loading complete in 25 ms. (kafka.log.LogManager)
[2019-04-15 17:46:32,514] INFO Loading logs. (kafka.log.LogManager)
[2019-04-15 17:46:32,531] INFO Logs loading complete in 17 ms. (kafka.log.LogManager)
[2019-04-15 17:46:32,530] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-04-15 17:46:32,537] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-04-15 17:46:32,563] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-04-15 17:46:32,571] INFO Log directory /tmp/kafka-logs not found, creating it. (kafka.log.LogManager)
[2019-04-15 17:46:32,581] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-04-15 17:46:32,585] INFO Loading logs. (kafka.log.LogManager)
[2019-04-15 17:46:32,607] INFO Logs loading complete in 22 ms. (kafka.log.LogManager)
[2019-04-15 17:46:32,654] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-04-15 17:46:32,684] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-04-15 17:46:33,597] INFO Awaiting socket connections on s0.0.0.0:9094. (kafka.network.Acceptor)
[2019-04-15 17:46:33,691] INFO Awaiting socket connections on s0.0.0.0:9092. (kafka.network.Acceptor)
[2019-04-15 17:46:33,795] INFO [SocketServer brokerId=2] Created data-plane acceptor and processors for endpoint : EndPoint(null,9094,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-04-15 17:46:33,806] INFO [SocketServer brokerId=2] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-04-15 17:46:33,841] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-04-15 17:46:33,852] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-04-15 17:46:33,896] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:46:33,935] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:46:33,935] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:46:33,949] INFO [ExpirationReaper-2-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:46:33,953] INFO Awaiting socket connections on s0.0.0.0:9093. (kafka.network.Acceptor)
[2019-04-15 17:46:33,959] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:46:33,975] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:46:33,982] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:46:33,967] ERROR [KafkaServer id=3] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.kafka.common.KafkaException: Socket server failed to bind to 0.0.0.0:9094: Address already in use.
	at kafka.network.Acceptor.openServerSocket(SocketServer.scala:573)
	at kafka.network.Acceptor.<init>(SocketServer.scala:451)
	at kafka.network.SocketServer.createAcceptor(SocketServer.scala:245)
	at kafka.network.SocketServer.$anonfun$createDataPlaneAcceptorsAndProcessors$1(SocketServer.scala:215)
	at kafka.network.SocketServer.$anonfun$createDataPlaneAcceptorsAndProcessors$1$adapted(SocketServer.scala:214)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at kafka.network.SocketServer.createDataPlaneAcceptorsAndProcessors(SocketServer.scala:214)
	at kafka.network.SocketServer.startup(SocketServer.scala:114)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:253)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:38)
	at kafka.Kafka$.main(Kafka.scala:75)
	at kafka.Kafka.main(Kafka.scala)
Caused by: java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:67)
	at kafka.network.Acceptor.openServerSocket(SocketServer.scala:569)
	... 13 more
[2019-04-15 17:46:33,999] INFO [KafkaServer id=3] shutting down (kafka.server.KafkaServer)
[2019-04-15 17:46:34,002] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:46:34,006] INFO [SocketServer brokerId=3] Stopping socket server request processors (kafka.network.SocketServer)
[2019-04-15 17:46:34,007] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-04-15 17:46:34,033] INFO [SocketServer brokerId=3] Stopped socket server request processors (kafka.network.SocketServer)
[2019-04-15 17:46:34,040] INFO Shutting down. (kafka.log.LogManager)
[2019-04-15 17:46:34,086] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-04-15 17:46:34,088] INFO [SocketServer brokerId=1] Created data-plane acceptor and processors for endpoint : EndPoint(null,9093,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-04-15 17:46:34,093] INFO [SocketServer brokerId=1] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-04-15 17:46:34,108] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-04-15 17:46:34,158] INFO Stat of the created znode at /brokers/ids/2 is: 73,73,1555314394143,1555314394143,1,0,0,72057652768669696,182,0,73
 (kafka.zk.KafkaZkClient)
[2019-04-15 17:46:34,160] INFO Registered broker 2 at path /brokers/ids/2 with addresses: ArrayBuffer(EndPoint(shodan,9094,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 73 (kafka.zk.KafkaZkClient)
[2019-04-15 17:46:34,166] WARN No meta.properties file under dir /tmp/kafka-logs-2/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-04-15 17:46:34,170] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:46:34,170] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:46:34,176] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:46:34,178] INFO Shutdown complete. (kafka.log.LogManager)
[2019-04-15 17:46:34,182] INFO [ZooKeeperClient] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-04-15 17:46:34,184] INFO Processed session termination for sessionid: 0x100000daca00001 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:46:34,185] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-04-15 17:46:34,187] INFO Session: 0x100000daca00001 closed (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:34,189] INFO [ZooKeeperClient] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-04-15 17:46:34,189] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:46:34,191] INFO EventThread shut down for session: 0x100000daca00001 (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:46:34,195] INFO Closed socket connection for client /127.0.0.1:36398 which had sessionid 0x100000daca00001 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-04-15 17:46:34,203] INFO [ExpirationReaper-1-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:46:34,227] INFO Stat of the created znode at /brokers/ids/0 is: 75,75,1555314394208,1555314394208,1,0,0,72057652768669699,182,0,75
 (kafka.zk.KafkaZkClient)
[2019-04-15 17:46:34,230] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(shodan,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 75 (kafka.zk.KafkaZkClient)
[2019-04-15 17:46:34,232] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-04-15 17:46:34,237] WARN No meta.properties file under dir /tmp/kafka-logs/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-04-15 17:46:34,264] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:46:34,264] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:46:34,264] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:46:34,268] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:46:34,268] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:46:34,268] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:46:34,276] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:46:34,277] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:46:34,281] INFO [SocketServer brokerId=3] Shutting down socket server (kafka.network.SocketServer)
[2019-04-15 17:46:34,394] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-04-15 17:46:34,420] INFO [SocketServer brokerId=3] Shutdown completed (kafka.network.SocketServer)
[2019-04-15 17:46:34,446] INFO [KafkaServer id=3] shut down completed (kafka.server.KafkaServer)
[2019-04-15 17:46:34,447] ERROR Exiting Kafka. (kafka.server.KafkaServerStartable)
[2019-04-15 17:46:34,452] INFO [KafkaServer id=3] shutting down (kafka.server.KafkaServer)
[2019-04-15 17:46:34,461] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:46:34,478] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[2019-04-15 17:46:34,502] INFO Stat of the created znode at /brokers/ids/1 is: 77,77,1555314394491,1555314394491,1,0,0,72057652768669698,182,0,77
 (kafka.zk.KafkaZkClient)
[2019-04-15 17:46:34,504] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(shodan,9093,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 77 (kafka.zk.KafkaZkClient)
[2019-04-15 17:46:34,508] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:46:34,508] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:46:34,537] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:46:34,537] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:46:34,538] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:46:34,542] INFO Got user-level KeeperException when processing sessionid:0x100000daca00003 type:multi cxid:0x19 zxid:0x4f txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/controller Error:KeeperErrorCode = NodeExists for /controller (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:46:34,593] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-04-15 17:46:34,596] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-04-15 17:46:34,609] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-04-15 17:46:34,635] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 35 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-04-15 17:46:34,627] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-04-15 17:46:34,643] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1 (kafka.coordinator.transaction.ProducerIdManager)
[2019-04-15 17:46:34,666] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 39 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-04-15 17:46:34,688] INFO [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:1000,blockEndProducerId:1999) by writing to Zk with path version 2 (kafka.coordinator.transaction.ProducerIdManager)
[2019-04-15 17:46:34,714] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-04-15 17:46:34,721] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-04-15 17:46:34,734] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-04-15 17:46:34,750] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:46:34,752] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:46:34,755] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:46:34,799] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-04-15 17:46:34,809] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-04-15 17:46:34,821] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-04-15 17:46:34,836] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-04-15 17:46:34,844] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 11 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-04-15 17:46:34,858] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-04-15 17:46:34,873] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:2000,blockEndProducerId:2999) by writing to Zk with path version 3 (kafka.coordinator.transaction.ProducerIdManager)
[2019-04-15 17:46:34,949] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-04-15 17:46:34,953] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-04-15 17:46:34,978] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-04-15 17:46:34,988] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-04-15 17:46:34,997] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2019-04-15 17:46:35,022] INFO Kafka version: 2.2.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-04-15 17:46:35,024] INFO Kafka commitId: 05fcfde8f69b0349 (org.apache.kafka.common.utils.AppInfoParser)
[2019-04-15 17:46:35,026] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2019-04-15 17:46:35,093] INFO Got user-level KeeperException when processing sessionid:0x100000daca00000 type:multi cxid:0x37 zxid:0x53 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:46:35,100] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-04-15 17:46:35,131] INFO [SocketServer brokerId=2] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2019-04-15 17:46:35,162] INFO Kafka version: 2.2.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-04-15 17:46:35,163] INFO Kafka commitId: 05fcfde8f69b0349 (org.apache.kafka.common.utils.AppInfoParser)
[2019-04-15 17:46:35,183] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2019-04-15 17:46:35,243] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-04-15 17:46:35,301] INFO [SocketServer brokerId=1] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2019-04-15 17:46:35,328] INFO Kafka version: 2.2.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-04-15 17:46:35,328] INFO Kafka commitId: 05fcfde8f69b0349 (org.apache.kafka.common.utils.AppInfoParser)
[2019-04-15 17:46:35,330] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2019-04-15 17:46:36,683] INFO Creating topic orderer with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(0, 1, 2)) (kafka.zk.AdminZkClient)
[2019-04-15 17:46:36,685] INFO Got user-level KeeperException when processing sessionid:0x100000daca00000 type:setData cxid:0x43 zxid:0x54 txntype:-1 reqpath:n/a Error Path:/config/topics/orderer Error:KeeperErrorCode = NoNode for /config/topics/orderer (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:46:36,838] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(orderer-0) (kafka.server.ReplicaFetcherManager)
[2019-04-15 17:46:36,850] INFO Replica loaded for partition orderer-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-04-15 17:46:36,857] INFO Replica loaded for partition orderer-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-04-15 17:46:36,866] INFO Replica loaded for partition orderer-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-04-15 17:46:36,968] INFO [Log partition=orderer-0, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-04-15 17:46:36,987] INFO [Log partition=orderer-0, dir=/tmp/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 77 ms (kafka.log.Log)
[2019-04-15 17:46:36,999] INFO Created log for partition orderer-0 in /tmp/kafka-logs-1 with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-04-15 17:46:37,012] INFO [Partition orderer-0 broker=1] No checkpointed highwatermark is found for partition orderer-0 (kafka.cluster.Partition)
[2019-04-15 17:46:37,014] INFO Replica loaded for partition orderer-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-04-15 17:46:37,016] INFO Replica loaded for partition orderer-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-04-15 17:46:37,023] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(orderer-0) (kafka.server.ReplicaFetcherManager)
[2019-04-15 17:46:37,029] INFO [Log partition=orderer-0, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-04-15 17:46:37,041] INFO [Log partition=orderer-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-04-15 17:46:37,057] INFO [Log partition=orderer-0, dir=/tmp/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 160 ms (kafka.log.Log)
[2019-04-15 17:46:37,077] INFO [Log partition=orderer-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 126 ms (kafka.log.Log)
[2019-04-15 17:46:37,085] INFO Created log for partition orderer-0 in /tmp/kafka-logs-2 with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-04-15 17:46:37,086] INFO Created log for partition orderer-0 in /tmp/kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-04-15 17:46:37,086] INFO [Partition orderer-0 broker=2] No checkpointed highwatermark is found for partition orderer-0 (kafka.cluster.Partition)
[2019-04-15 17:46:37,087] INFO Replica loaded for partition orderer-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-04-15 17:46:37,087] INFO [Partition orderer-0 broker=0] No checkpointed highwatermark is found for partition orderer-0 (kafka.cluster.Partition)
[2019-04-15 17:46:37,091] INFO Replica loaded for partition orderer-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-04-15 17:46:37,093] INFO Replica loaded for partition orderer-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-04-15 17:46:37,093] INFO Replica loaded for partition orderer-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-04-15 17:46:37,095] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(orderer-0) (kafka.server.ReplicaFetcherManager)
[2019-04-15 17:46:37,100] INFO [Partition orderer-0 broker=0] orderer-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-04-15 17:46:37,134] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=0, host=shodan:9092) for partitions Map(orderer-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-04-15 17:46:37,136] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-04-15 17:46:37,189] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=0, host=shodan:9092) for partitions Map(orderer-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-04-15 17:46:37,192] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition orderer-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-04-15 17:46:37,197] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-04-15 17:46:37,208] INFO [Log partition=orderer-0, dir=/tmp/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-04-15 17:46:37,253] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition orderer-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-04-15 17:46:37,278] INFO [Log partition=orderer-0, dir=/tmp/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-04-15 17:46:50,282] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-04-15 17:46:50,288] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2019-04-15 17:46:50,289] INFO [KafkaServer id=1] Starting controlled shutdown (kafka.server.KafkaServer)
[2019-04-15 17:46:50,319] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set() (kafka.server.ReplicaFetcherManager)
[2019-04-15 17:46:50,320] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set() (kafka.server.ReplicaAlterLogDirsManager)
[2019-04-15 17:46:50,341] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(orderer-0) (kafka.server.ReplicaFetcherManager)
[2019-04-15 17:46:50,341] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(orderer-0) (kafka.server.ReplicaAlterLogDirsManager)
[2019-04-15 17:46:50,345] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2019-04-15 17:46:50,350] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Error sending fetch request (sessionId=1931647576, epoch=25) to node 0: java.io.IOException: Client was shutdown before response was read. (org.apache.kafka.clients.FetchSessionHandler)
[2019-04-15 17:46:50,350] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2019-04-15 17:46:50,352] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2019-04-15 17:46:50,400] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(orderer-0) (kafka.server.ReplicaFetcherManager)
[2019-04-15 17:46:50,401] INFO [Partition orderer-0 broker=0] orderer-0 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-04-15 17:46:50,403] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set() (kafka.server.ReplicaFetcherManager)
[2019-04-15 17:46:50,403] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set() (kafka.server.ReplicaAlterLogDirsManager)
[2019-04-15 17:46:50,404] WARN [LeaderEpochCache orderer-0] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-04-15 17:46:50,399] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(orderer-0) (kafka.server.ReplicaFetcherManager)
[2019-04-15 17:46:50,407] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=0, host=shodan:9092) for partitions Map(orderer-0 -> (offset=0, leaderEpoch=1)) (kafka.server.ReplicaFetcherManager)
[2019-04-15 17:46:50,407] INFO [KafkaServer id=1] Controlled shutdown succeeded (kafka.server.KafkaServer)
[2019-04-15 17:46:50,410] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(orderer-0) (kafka.server.ReplicaFetcherManager)
[2019-04-15 17:46:50,410] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(orderer-0) (kafka.server.ReplicaAlterLogDirsManager)
[2019-04-15 17:46:50,419] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-04-15 17:46:50,420] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-04-15 17:46:50,420] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-04-15 17:46:50,422] INFO [SocketServer brokerId=1] Stopping socket server request processors (kafka.network.SocketServer)
[2019-04-15 17:46:50,444] INFO [SocketServer brokerId=1] Stopped socket server request processors (kafka.network.SocketServer)
[2019-04-15 17:46:50,447] INFO [data-plane Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
[2019-04-15 17:46:50,452] INFO [data-plane Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2019-04-15 17:46:50,457] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
[2019-04-15 17:46:50,465] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:46:50,569] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:46:50,569] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:46:50,575] INFO [TransactionCoordinator id=1] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-04-15 17:46:50,577] INFO [ProducerId Manager 1]: Shutdown complete: last producerId assigned 2000 (kafka.coordinator.transaction.ProducerIdManager)
[2019-04-15 17:46:50,578] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2019-04-15 17:46:50,579] INFO [Transaction Marker Channel Manager 1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-04-15 17:46:50,583] INFO [Transaction Marker Channel Manager 1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-04-15 17:46:50,584] INFO [Transaction Marker Channel Manager 1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-04-15 17:46:50,584] INFO [TransactionCoordinator id=1] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-04-15 17:46:50,586] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2019-04-15 17:46:50,587] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:46:50,637] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition orderer-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-04-15 17:46:50,638] INFO [Log partition=orderer-0, dir=/tmp/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-04-15 17:46:50,769] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:46:50,769] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:46:50,770] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:46:50,966] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:46:50,966] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:46:50,968] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2019-04-15 17:46:50,973] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
[2019-04-15 17:46:50,974] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-04-15 17:46:50,975] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-04-15 17:46:50,975] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-04-15 17:46:50,976] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2019-04-15 17:46:50,978] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2019-04-15 17:46:50,981] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2019-04-15 17:46:50,982] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2019-04-15 17:46:50,982] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:46:50,996] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:46:50,996] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:46:50,996] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:46:51,186] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:46:51,186] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:46:51,187] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:46:51,199] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:46:51,199] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:46:51,200] INFO [ExpirationReaper-1-ElectPreferredLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:46:51,282] INFO [ExpirationReaper-1-ElectPreferredLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:46:51,283] INFO [ExpirationReaper-1-ElectPreferredLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:46:51,298] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
[2019-04-15 17:46:51,299] INFO Shutting down. (kafka.log.LogManager)
[2019-04-15 17:46:51,382] INFO Shutdown complete. (kafka.log.LogManager)
[2019-04-15 17:46:51,394] INFO [ZooKeeperClient] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-04-15 17:46:51,396] INFO Processed session termination for sessionid: 0x100000daca00002 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:46:51,399] INFO Session: 0x100000daca00002 closed (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:51,399] INFO EventThread shut down for session: 0x100000daca00002 (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:46:51,401] INFO Closed socket connection for client /127.0.0.1:36400 which had sessionid 0x100000daca00002 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-04-15 17:46:51,402] INFO [ZooKeeperClient] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-04-15 17:46:51,403] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:46:52,379] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:46:52,379] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:46:52,380] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:46:52,385] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:46:52,385] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:46:52,385] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:46:52,401] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:46:52,401] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:46:52,404] INFO [SocketServer brokerId=1] Shutting down socket server (kafka.network.SocketServer)
[2019-04-15 17:46:52,454] INFO [SocketServer brokerId=1] Shutdown completed (kafka.network.SocketServer)
[2019-04-15 17:46:52,459] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
[2019-04-15 17:46:53,636] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-04-15 17:46:53,639] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)
[2019-04-15 17:46:53,640] INFO [KafkaServer id=2] Starting controlled shutdown (kafka.server.KafkaServer)
[2019-04-15 17:46:53,656] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set() (kafka.server.ReplicaFetcherManager)
[2019-04-15 17:46:53,656] INFO [ReplicaAlterLogDirsManager on broker 2] Removed fetcher for partitions Set() (kafka.server.ReplicaAlterLogDirsManager)
[2019-04-15 17:46:53,660] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(orderer-0) (kafka.server.ReplicaFetcherManager)
[2019-04-15 17:46:53,660] INFO [ReplicaAlterLogDirsManager on broker 2] Removed fetcher for partitions Set(orderer-0) (kafka.server.ReplicaAlterLogDirsManager)
[2019-04-15 17:46:53,662] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2019-04-15 17:46:53,664] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Error sending fetch request (sessionId=697713392, epoch=31) to node 0: java.io.IOException: Client was shutdown before response was read. (org.apache.kafka.clients.FetchSessionHandler)
[2019-04-15 17:46:53,664] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2019-04-15 17:46:53,667] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2019-04-15 17:46:53,678] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(orderer-0) (kafka.server.ReplicaFetcherManager)
[2019-04-15 17:46:53,678] INFO [Partition orderer-0 broker=0] orderer-0 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-04-15 17:46:53,680] WARN [LeaderEpochCache orderer-0] New epoch entry EpochEntry(epoch=2, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=1, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-04-15 17:46:53,685] INFO [KafkaServer id=2] Controlled shutdown succeeded (kafka.server.KafkaServer)
[2019-04-15 17:46:53,688] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set() (kafka.server.ReplicaFetcherManager)
[2019-04-15 17:46:53,688] INFO [ReplicaAlterLogDirsManager on broker 2] Removed fetcher for partitions Set() (kafka.server.ReplicaAlterLogDirsManager)
[2019-04-15 17:46:53,693] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(orderer-0) (kafka.server.ReplicaFetcherManager)
[2019-04-15 17:46:53,693] INFO [ReplicaAlterLogDirsManager on broker 2] Removed fetcher for partitions Set(orderer-0) (kafka.server.ReplicaAlterLogDirsManager)
[2019-04-15 17:46:53,699] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-04-15 17:46:53,700] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-04-15 17:46:53,700] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-04-15 17:46:53,702] INFO [SocketServer brokerId=2] Stopping socket server request processors (kafka.network.SocketServer)
[2019-04-15 17:46:53,717] INFO [SocketServer brokerId=2] Stopped socket server request processors (kafka.network.SocketServer)
[2019-04-15 17:46:53,719] INFO [data-plane Kafka Request Handler on Broker 2], shutting down (kafka.server.KafkaRequestHandlerPool)
[2019-04-15 17:46:53,722] INFO [data-plane Kafka Request Handler on Broker 2], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2019-04-15 17:46:53,726] INFO [KafkaApi-2] Shutdown complete. (kafka.server.KafkaApis)
[2019-04-15 17:46:53,728] INFO [ExpirationReaper-2-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:46:53,886] INFO [ExpirationReaper-2-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:46:53,886] INFO [ExpirationReaper-2-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:46:53,892] INFO [TransactionCoordinator id=2] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-04-15 17:46:53,894] INFO [ProducerId Manager 2]: Shutdown complete: last producerId assigned 1000 (kafka.coordinator.transaction.ProducerIdManager)
[2019-04-15 17:46:53,895] INFO [Transaction State Manager 2]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2019-04-15 17:46:53,895] INFO [Transaction Marker Channel Manager 2]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-04-15 17:46:53,899] INFO [Transaction Marker Channel Manager 2]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-04-15 17:46:53,903] INFO [Transaction Marker Channel Manager 2]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-04-15 17:46:53,904] INFO [TransactionCoordinator id=2] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-04-15 17:46:53,905] INFO [GroupCoordinator 2]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2019-04-15 17:46:53,911] INFO [ExpirationReaper-2-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:46:53,938] INFO [ExpirationReaper-2-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:46:53,938] INFO [ExpirationReaper-2-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:46:53,939] INFO [ExpirationReaper-2-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:46:53,944] INFO [ExpirationReaper-2-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:46:53,944] INFO [ExpirationReaper-2-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:46:53,945] INFO [GroupCoordinator 2]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2019-04-15 17:46:53,948] INFO [ReplicaManager broker=2] Shutting down (kafka.server.ReplicaManager)
[2019-04-15 17:46:53,948] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-04-15 17:46:53,949] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-04-15 17:46:53,950] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-04-15 17:46:53,951] INFO [ReplicaFetcherManager on broker 2] shutting down (kafka.server.ReplicaFetcherManager)
[2019-04-15 17:46:53,957] INFO [ReplicaFetcherManager on broker 2] shutdown completed (kafka.server.ReplicaFetcherManager)
[2019-04-15 17:46:53,958] INFO [ReplicaAlterLogDirsManager on broker 2] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2019-04-15 17:46:53,959] INFO [ReplicaAlterLogDirsManager on broker 2] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2019-04-15 17:46:53,959] INFO [ExpirationReaper-2-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:46:53,962] INFO [ExpirationReaper-2-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:46:53,962] INFO [ExpirationReaper-2-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:46:53,963] INFO [ExpirationReaper-2-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:46:54,115] INFO [ExpirationReaper-2-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:46:54,115] INFO [ExpirationReaper-2-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:46:54,116] INFO [ExpirationReaper-2-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:46:54,164] INFO [ExpirationReaper-2-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:46:54,164] INFO [ExpirationReaper-2-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:46:54,165] INFO [ExpirationReaper-2-ElectPreferredLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:46:54,364] INFO [ExpirationReaper-2-ElectPreferredLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:46:54,365] INFO [ExpirationReaper-2-ElectPreferredLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-04-15 17:46:54,373] INFO [ReplicaManager broker=2] Shut down completely (kafka.server.ReplicaManager)
[2019-04-15 17:46:54,374] INFO Shutting down. (kafka.log.LogManager)
[2019-04-15 17:46:54,469] INFO Shutdown complete. (kafka.log.LogManager)
[2019-04-15 17:46:54,486] INFO [ZooKeeperClient] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-04-15 17:46:54,488] INFO Processed session termination for sessionid: 0x100000daca00000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:46:54,492] INFO Session: 0x100000daca00000 closed (org.apache.zookeeper.ZooKeeper)
[2019-04-15 17:46:54,492] INFO EventThread shut down for session: 0x100000daca00000 (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:46:54,495] INFO Closed socket connection for client /127.0.0.1:36396 which had sessionid 0x100000daca00000 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-04-15 17:46:54,498] INFO [ZooKeeperClient] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-04-15 17:46:54,500] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:46:54,637] INFO Got user-level KeeperException when processing sessionid:0x100000daca00003 type:multi cxid:0x3d zxid:0x5f txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-04-15 17:46:55,449] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:46:55,449] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:46:55,449] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:46:55,450] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:46:55,450] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:46:55,450] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:46:55,453] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:46:55,453] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-04-15 17:46:55,457] INFO [SocketServer brokerId=2] Shutting down socket server (kafka.network.SocketServer)
[2019-04-15 17:46:55,501] INFO [SocketServer brokerId=2] Shutdown completed (kafka.network.SocketServer)
[2019-04-15 17:46:55,505] INFO [KafkaServer id=2] shut down completed (kafka.server.KafkaServer)
[2019-04-15 17:46:55,622] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-04-15 17:46:55,625] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2019-04-15 17:46:55,627] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2019-04-15 17:46:55,696] INFO [KafkaServer id=0] Remaining partitions to move: orderer-0 (kafka.server.KafkaServer)
[2019-04-15 17:46:55,697] INFO [KafkaServer id=0] Error from controller: NONE (kafka.server.KafkaServer)
[2019-04-15 17:47:00,698] WARN [KafkaServer id=0] Retrying controlled shutdown after the previous attempt failed... (kafka.server.KafkaServer)
[2019-04-15 17:47:00,709] INFO [KafkaServer id=0] Remaining partitions to move: orderer-0 (kafka.server.KafkaServer)
[2019-04-15 17:47:00,709] INFO [KafkaServer id=0] Error from controller: NONE (kafka.server.KafkaServer)
[2019-04-15 17:47:00,927] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-04-15 17:47:03,562] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-04-15 17:47:04,543] INFO Unable to read additional data from server sessionid 0x100000daca00003, likely server has closed socket, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:47:05,709] WARN [KafkaServer id=0] Retrying controlled shutdown after the previous attempt failed... (kafka.server.KafkaServer)
[2019-04-15 17:47:06,333] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:47:06,334] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:47:06,437] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-04-15 17:47:06,670] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-04-15 17:47:08,247] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:47:08,248] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:47:10,198] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:47:10,198] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:47:11,509] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:47:11,510] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:47:13,282] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:47:13,283] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:47:14,503] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:47:14,504] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:47:16,452] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:47:16,453] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:47:17,940] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:47:17,941] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:47:19,682] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:47:19,683] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:47:21,348] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:47:21,349] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:47:23,224] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:47:23,225] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:47:24,790] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:47:24,791] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:47:26,492] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:47:26,493] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:47:27,867] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:47:27,868] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:47:29,305] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:47:29,306] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:47:30,966] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:47:30,967] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:47:32,762] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:47:32,763] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:47:34,529] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:47:34,530] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:47:36,066] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:47:36,067] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:47:37,917] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:47:37,918] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:47:39,353] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:47:39,354] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:47:40,466] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:47:40,467] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:47:42,021] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:47:42,022] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:47:44,007] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:47:44,008] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:47:45,945] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:47:45,946] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:47:47,361] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:47:47,362] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:47:49,391] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:47:49,392] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:47:50,579] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:47:50,580] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:47:52,579] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:47:52,580] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:47:54,019] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:47:54,020] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:47:55,754] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:47:55,756] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:47:57,570] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:47:57,571] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:47:59,196] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:47:59,197] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:00,326] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:00,326] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:02,246] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:02,246] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:04,051] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:04,052] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:05,649] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:05,650] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:06,808] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:06,809] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:08,563] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:08,564] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:10,442] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:10,443] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:12,398] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:12,399] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:14,183] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:14,184] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:15,421] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:15,422] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:16,706] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:16,707] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:18,743] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:18,744] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:20,494] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:20,495] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:22,566] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:22,567] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:23,799] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:23,800] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:25,477] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:25,478] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:27,356] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:27,357] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:29,039] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:29,040] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:30,228] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:30,229] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:31,758] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:31,759] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:33,251] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:33,252] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:34,991] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:34,992] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:36,450] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:36,451] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:38,262] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:38,263] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:39,800] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:39,801] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:41,313] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:41,315] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:43,208] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:43,209] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:44,592] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:44,593] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:46,072] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:46,073] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:47,794] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:47,795] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:49,368] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:49,369] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:51,455] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:51,456] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:52,921] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:52,922] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:54,398] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:54,399] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:56,252] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:56,253] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:57,815] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:57,816] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:59,095] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:48:59,096] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:00,877] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:00,878] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:02,353] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:02,354] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:03,880] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:03,881] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:05,433] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:05,434] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:07,177] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:07,178] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:09,014] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:09,015] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:10,676] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:10,676] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:12,194] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:12,195] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:13,698] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:13,698] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:15,573] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:15,574] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:17,049] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:17,050] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:18,584] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:18,585] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:19,877] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:19,878] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:21,670] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:21,671] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:22,800] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:22,801] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:24,243] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:24,243] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:26,138] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:26,139] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:27,310] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:27,311] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:29,220] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:29,221] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:31,153] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:31,154] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:33,214] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:33,215] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:35,196] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:35,197] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:36,503] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:36,504] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:38,457] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:38,458] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:39,893] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:39,893] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:41,003] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:41,004] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:42,437] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:42,438] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:44,112] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:44,112] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:45,965] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:45,966] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:47,840] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:47,841] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:49,183] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:49,184] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:50,946] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:50,947] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:52,416] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:52,417] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:54,067] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:54,068] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:55,952] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:55,953] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:57,481] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:57,482] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:58,884] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:49:58,885] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:00,632] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:00,633] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:02,577] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:02,578] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:04,572] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:04,573] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:05,739] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:05,740] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:07,789] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:07,790] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:09,621] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:09,622] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:11,095] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:11,096] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:12,657] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:12,658] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:14,448] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:14,449] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:16,118] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:16,119] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:17,827] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:17,828] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:19,468] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:19,469] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:21,525] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:21,525] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:22,880] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:22,881] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:24,014] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:24,014] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:25,130] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:25,131] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:26,365] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-04-15 17:50:26,504] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:26,505] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:28,557] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:28,558] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:30,053] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-04-15 17:50:30,381] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:30,381] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:30,588] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-04-15 17:50:30,971] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-04-15 17:50:31,156] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-04-15 17:50:31,338] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-04-15 17:50:31,907] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:31,908] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:32,991] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-04-15 17:50:33,340] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-04-15 17:50:33,525] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-04-15 17:50:33,692] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-04-15 17:50:33,859] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-04-15 17:50:33,941] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:33,942] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:34,026] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-04-15 17:50:35,826] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:35,827] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:37,436] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:37,437] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:38,163] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-04-15 17:50:38,697] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-04-15 17:50:39,180] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-04-15 17:50:39,403] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:39,404] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:39,596] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-04-15 17:50:40,115] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-04-15 17:50:40,469] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-04-15 17:50:40,832] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-04-15 17:50:41,098] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-04-15 17:50:41,317] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-04-15 17:50:41,348] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:41,349] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:41,516] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-04-15 17:50:42,955] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:42,955] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:44,703] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:44,704] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:46,577] INFO Terminating process due to signal SIGINT (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-04-15 17:50:46,733] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:46,734] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:47,216] INFO Terminating process due to signal SIGINT (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-04-15 17:50:47,448] INFO Terminating process due to signal SIGINT (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-04-15 17:50:47,638] INFO Terminating process due to signal SIGINT (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-04-15 17:50:47,796] INFO Terminating process due to signal SIGINT (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-04-15 17:50:47,947] INFO Terminating process due to signal SIGINT (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-04-15 17:50:48,112] INFO Terminating process due to signal SIGINT (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-04-15 17:50:48,267] INFO Terminating process due to signal SIGINT (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-04-15 17:50:48,701] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:48,702] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:50,270] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:50,271] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:51,583] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:51,584] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:51,690] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-04-15 17:50:53,556] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:53,556] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:54,937] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:54,939] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:55,814] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-04-15 17:50:56,360] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:56,361] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:57,743] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:57,743] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:59,826] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:50:59,827] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:01,001] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:01,002] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:02,929] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:02,930] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:04,983] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:04,983] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:06,654] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:06,654] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:08,717] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:08,718] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:10,532] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:10,533] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:12,204] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:12,205] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:14,129] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:14,130] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:15,751] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:15,753] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:17,307] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:17,308] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:17,604] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-04-15 17:51:18,255] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-04-15 17:51:18,554] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:18,555] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:18,624] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-04-15 17:51:18,790] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-04-15 17:51:18,959] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-04-15 17:51:19,142] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-04-15 17:51:19,309] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-04-15 17:51:19,493] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-04-15 17:51:19,660] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-04-15 17:51:19,843] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-04-15 17:51:20,630] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:20,631] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:21,759] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:21,759] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:22,964] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-04-15 17:51:22,978] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-04-15 17:51:23,080] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:23,081] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:24,936] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:24,937] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:26,858] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:26,859] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:28,794] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:28,795] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:30,072] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:30,073] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:31,507] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:31,508] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:33,059] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:33,060] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:34,727] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:34,728] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:35,893] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:35,894] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:37,391] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:37,392] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:39,440] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:39,441] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:41,030] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:41,031] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:42,990] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:42,990] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:45,090] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:45,090] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:47,091] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:47,092] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:48,967] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:48,968] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:50,542] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:50,543] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:52,083] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:52,084] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:53,533] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:53,533] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:55,466] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:55,467] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:57,552] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:57,553] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:59,382] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:51:59,383] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:00,779] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:00,780] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:02,130] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:02,131] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:03,236] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:03,237] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:04,627] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:04,628] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:05,753] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:05,754] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:07,120] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:07,121] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:08,453] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:08,454] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:10,434] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:10,435] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:11,564] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:11,565] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:13,065] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:13,066] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:14,462] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:14,463] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:15,877] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:15,878] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:17,077] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:17,077] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:18,847] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:18,847] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:20,935] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:20,935] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:22,152] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:22,153] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:23,729] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:23,730] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:25,386] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:25,387] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:27,451] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:27,452] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:29,472] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:29,473] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:31,133] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:31,134] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:32,703] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:32,704] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:34,282] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:34,283] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:36,144] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:36,145] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:38,180] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:38,181] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:40,272] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:40,273] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:41,529] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:41,530] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:43,397] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:43,398] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:44,730] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:44,731] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:46,758] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:46,759] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:48,069] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:48,070] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:50,162] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:50,163] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:51,504] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:51,505] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:53,090] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-04-15 17:52:53,091] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
